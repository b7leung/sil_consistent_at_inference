{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:51:34.619134Z",
     "start_time": "2021-01-21T02:51:34.544686Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:51:35.126638Z",
     "start_time": "2021-01-21T02:51:35.108681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/CVPR_2021_REFINE/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:51:52.462822Z",
     "start_time": "2021-01-21T02:51:46.306519Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "import pytorch3d.transforms\n",
    "import PIL\n",
    "from scipy import ndimage\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from utils import general_utils\n",
    "\n",
    "#from evaluation import compute_iou_2d, compute_iou_2d_given_pose, compute_iou_3d, compute_chamfer_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:51:52.615804Z",
     "start_time": "2021-01-21T02:51:52.503901Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# reverse engineered from \n",
    "# https://pytorch3d.readthedocs.io/en/latest/_modules/pytorch3d/renderer/cameras.html#camera_position_from_spherical_angles\n",
    "def cart_to_spherical(cart_coords):\n",
    "    x = cart_coords[0]\n",
    "    y = cart_coords[1]\n",
    "    z = cart_coords[2]\n",
    "    \n",
    "    dist = np.sqrt(x**2 + y**2 + z**2)\n",
    "    elev = np.arcsin(y)/dist\n",
    "    #azim = np.arctan(x/z)\n",
    "    azim = np.arctan(x/z) + np.pi\n",
    "    return dist, elev, azim\n",
    "    \n",
    "def spherical_to_cart(dist, elev, azim):\n",
    "    x = dist * np.cos(elev) * np.sin(azim)\n",
    "    y = dist * np.sin(elev)\n",
    "    z = dist * np.cos(elev) * np.cos(azim)\n",
    "    print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:51:52.732376Z",
     "start_time": "2021-01-21T02:51:52.618445Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# assumes cam_pos is a vector of numbers\n",
    "def find_best_fitting_cam_pos(mesh, cam_pos, num_dists, device, batch_size=8):\n",
    "    # normalizing\n",
    "    with torch.no_grad():\n",
    "        eyes = [cam_pos*i for i in np.geomspace(0.005, 2, num_dists)]\n",
    "        R, T = look_at_view_transform(eye=eyes)\n",
    "        meshes = mesh.extend(num_dists)\n",
    "        renders = utils.render_mesh(meshes, R, T, device)\n",
    "        \n",
    "        rendered_image_fits = []\n",
    "        for i in range(renders.shape[0]):\n",
    "            rendered_image_fits.append(rgba_obj_in_frame(renders[i].cpu().numpy()))\n",
    "\n",
    "        # choose closest cam_pos, whose rendered image will fit completely in the frame\n",
    "        i = 0\n",
    "        while not rendered_image_fits[i]:\n",
    "            i+=1\n",
    "\n",
    "        best_cam_pos = eyes[i]\n",
    "        \n",
    "    return best_cam_pos\n",
    "\n",
    "def get_iou(mask1, mask2):\n",
    "    intersect = mask1 * mask2 # Logical AND\n",
    "    union = mask1 + mask2 # Logical OR\n",
    "    IOU = intersect.sum()/float(union.sum())\n",
    "    return IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:52:19.019820Z",
     "start_time": "2021-01-21T02:52:18.706511Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_pix3d_image(curr_info_dict, visualize=False, inplane=True, use_spherical=True):\n",
    "    #pprint.pprint(curr_info_dict)\n",
    "    img_path = os.path.join(PIX3D_PATH, curr_info_dict[\"img\"])\n",
    "    mesh_path = os.path.join(PIX3D_PATH, curr_info_dict[\"model\"])\n",
    "    mask_path = os.path.join(PIX3D_PATH, curr_info_dict[\"mask\"])\n",
    "    cam_pos = curr_info_dict[\"cam_position\"]\n",
    "    theta = curr_info_dict[\"inplane_rotation\"]\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # processing pose ---------------------------------------------------\n",
    "    mesh = general_utils.load_untextured_mesh(mesh_path, device)\n",
    "    \n",
    "    up_axis = [0,1,0] \n",
    "    if inplane:\n",
    "        theta = curr_info_dict[\"inplane_rotation\"]\n",
    "        inplane_R = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta),0],[0,0,1]])\n",
    "        up_axis = (inplane_R@np.array([up_axis]).T).T[0]\n",
    "\n",
    "    # obtaining GT pose in spherical coordinates\n",
    "    cam_pos = np.array(cam_pos)/np.sqrt(cam_pos[0]**2+cam_pos[1]**2+cam_pos[2]**2)\n",
    "    dist, elev, azim = cart_to_spherical(cam_pos)\n",
    "    azim = azim * (180/np.pi) \n",
    "    elev = elev * (180/np.pi) \n",
    "    R, T = look_at_view_transform(dist,elev,azim, up=[up_axis])\n",
    "    spherical_based_render = general_utils.render_mesh(mesh, R, T, device, img_size=img_size)\n",
    "\n",
    "    # double checking spherical coordinates conversion to see it it matches camera position based pose\n",
    "    # Note sure why this is necessary\n",
    "    R, T = look_at_view_transform(eye=[cam_pos], up=[up_axis])\n",
    "    cam_based_render = general_utils.render_mesh(mesh, R, T, device, img_size=img_size)\n",
    "    render_comparision_iou = get_iou(spherical_based_render[0,...,3]>0, cam_based_render[0,...,3]>0)\n",
    "    flipped=False\n",
    "    if render_comparision_iou.item() < 0.95:\n",
    "        azim += 180\n",
    "        R, T = look_at_view_transform(dist,elev,azim, up=[up_axis])\n",
    "        spherical_based_render = general_utils.render_mesh(mesh, R, T, device, img_size=img_size)\n",
    "        flipped=True\n",
    "   \n",
    "    # processing image ---------------------------------------------------\n",
    "    bbox = curr_info_dict[\"bbox\"]\n",
    "    \n",
    "    # masking and cropping image\n",
    "    mask = Image.open(mask_path)\n",
    "    img_masked_rgba = Image.composite(Image.new(\"RGBA\", curr_info_dict['img_size']), img.convert('RGBA'), PIL.ImageOps.invert(mask))\n",
    "    img_masked_rgba = img_masked_rgba.crop(bbox)\n",
    "    \n",
    "    # resizing and placing the masked image so that it best fits the render\n",
    "    objs = ndimage.find_objects(spherical_based_render[0,...,3].detach().cpu().numpy()>0.2)\n",
    "    render_bbox = [objs[0][1].start, objs[0][0].start, objs[0][1].stop, objs[0][0].stop] # upper left, lower right\n",
    "    render_bbox_width = render_bbox[2] - render_bbox[0]\n",
    "    render_bbox_height = render_bbox[3] - render_bbox[1]\n",
    "    # recording resizing ratio\n",
    "    resize_width_ratio = render_bbox_width/img_masked_rgba.size[0] # width, height = im.size\n",
    "    resize_height_ratio = render_bbox_height/img_masked_rgba.size[1]\n",
    "    img_masked_rgba_resized = img_masked_rgba.resize((render_bbox_width, render_bbox_height))\n",
    "    processed_img = Image.new(\"RGBA\", (img_size, img_size))\n",
    "    processed_img.paste(img_masked_rgba_resized, box=render_bbox[:2])\n",
    "\n",
    "    # getting unmasked version by applying the same scaling and cropping transformations\n",
    "    img_unmasked_rgba = img.convert('RGBA')\n",
    "    #plt.imshow(img_unmasked_rgba)\n",
    "    #plt.show()\n",
    "    xc_before = img_unmasked_rgba.size[0]/2\n",
    "    yc_before = img_unmasked_rgba.size[1]/2\n",
    "    img_unmasked_rgba = img_unmasked_rgba.resize((int(img_unmasked_rgba.size[0]*resize_width_ratio), int(img_unmasked_rgba.size[1]*resize_height_ratio)))\n",
    "    # based on https://math.stackexchange.com/questions/109122/how-do-i-calculate-the-new-x-y-coordinates-and-width-height-of-a-re-sized-group\n",
    "    xc = img_unmasked_rgba.size[0]/2\n",
    "    yc = img_unmasked_rgba.size[1]/2\n",
    "    #print(\"BEFORE RESIZE xc: {}, yc: {}\".format(xc_before, yc_before))\n",
    "    #print(\"AFTER RESIZE xc: {}, yc: {}\".format(xc, yc))\n",
    "    #print(\"rw: {}, rh: {}\".format(resize_width_ratio, resize_height_ratio))\n",
    "    u_bbox = [int(xc+resize_width_ratio*(bbox[0]-xc_before)), int(yc+resize_height_ratio*(bbox[1]-yc_before)), int(xc+resize_width_ratio*(bbox[2]-xc_before)), int(yc+resize_height_ratio*(bbox[3]-yc_before))]\n",
    "    u_bbox = [u_bbox[0]-render_bbox[0], u_bbox[1]-render_bbox[1], u_bbox[2], u_bbox[3]]\n",
    "    u_bbox = [u_bbox[0], u_bbox[1], u_bbox[2]+(img_size-(u_bbox[2]-u_bbox[0])), u_bbox[3]+(img_size-(u_bbox[3]-u_bbox[1]))]\n",
    "    img_unmasked_rgba_cropped = img_unmasked_rgba.crop(u_bbox)\n",
    "    \n",
    "    \n",
    "    final_iou = get_iou(spherical_based_render[0, ..., 3].detach().cpu().numpy() > 0, np.array(processed_img)[...,3]>0)\n",
    "    if visualize:\n",
    "        #plt.imshow(img_masked_rgba)\n",
    "        #plt.show()\n",
    "        #plt.imshow(spherical_based_render[0, ..., :3].detach().cpu().numpy())\n",
    "        #plt.show()\n",
    "        plt.imshow(processed_img)\n",
    "        plt.show()\n",
    "        \n",
    "        #plt.imshow(img_unmasked_rgba)\n",
    "        #plt.show()\n",
    "        plt.imshow(img_unmasked_rgba_cropped)\n",
    "        plt.show()\n",
    "    return processed_img, img_unmasked_rgba_cropped, dist, elev, azim, final_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:52:20.439710Z",
     "start_time": "2021-01-21T02:52:20.344490Z"
    }
   },
   "outputs": [],
   "source": [
    "pix3d_class = \"chair\"\n",
    "\n",
    "PIX3D_PATH = \"/home/svcl-oowl/dataset/pix3d\"\n",
    "PROCESSED_PIX3D_PATH = \"data/pix3d_images_processed_bg_test\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "img_size = 224\n",
    "blacklist = [\"img/table/0045\", \"img/table/1749\"]\n",
    "recompute=False\n",
    "\n",
    "processed_class_output_dir = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class, \"rgba\")\n",
    "os.makedirs(processed_class_output_dir, exist_ok=True)\n",
    "processed_class_output_dir_rgb = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class, \"rgb\")\n",
    "os.makedirs(processed_class_output_dir_rgb, exist_ok=True)\n",
    "processed_class_output_dir_unmasked = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class, \"unmasked\")\n",
    "os.makedirs(processed_class_output_dir_unmasked, exist_ok=True)\n",
    "\n",
    "pose_dict_path = os.path.join(processed_class_output_dir, \"renders_camera_params.pt\")\n",
    "iou_dict_path = os.path.join(processed_class_output_dir, \"iou_info.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T02:52:25.440303Z",
     "start_time": "2021-01-21T02:52:22.357662Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PIX3D_PATH, \"pix3d.json\")) as f:\n",
    "    pix3d_data_json = json.loads(f.read())\n",
    "# convert list of dicts into a dict (keyed by image path) of dicts\n",
    "pix3d_data_dict = { entry[\"img\"].split('.')[0]:entry for entry in pix3d_data_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:36:18.345495Z",
     "start_time": "2021-01-21T02:52:29.010532Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a022d829617f4bbaa3b3fc9f4809daaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3839.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(pose_dict_path):\n",
    "    pose_dict = pickle.load(open(pose_dict_path, \"rb\"))\n",
    "else:\n",
    "    pose_dict = {}\n",
    "    \n",
    "if os.path.exists(iou_dict_path):\n",
    "    iou_dict = pickle.load(open(iou_dict_path, \"rb\"))\n",
    "else:\n",
    "    iou_dict = {}\n",
    "\n",
    "class_instance_names = [instance_name for instance_name in pix3d_data_dict.keys() if pix3d_class in instance_name]\n",
    "for instance_name in tqdm(class_instance_names):\n",
    "    instance_class_id = instance_name.split('/')[-1]\n",
    "    processed_img_path = os.path.join(processed_class_output_dir, \"{}.png\".format(instance_class_id))\n",
    "    processed_unmasked_img_path = os.path.join(processed_class_output_dir_unmasked, \"{}.png\".format(instance_class_id))\n",
    "    if instance_name not in blacklist and (recompute or not os.path.exists(processed_img_path)):\n",
    "        masked_processed_img, unmasked_processed_img, dist, elev, azim, iou = process_pix3d_image(pix3d_data_dict[instance_name], visualize=False)\n",
    "        iou_dict[instance_class_id] = iou\n",
    "        pose_dict[instance_class_id] = {\"azim\": azim, \"elev\": elev, \"dist\": dist}\n",
    "        pickle.dump(iou_dict, open(iou_dict_path, \"wb\"))\n",
    "        pickle.dump(pose_dict, open(pose_dict_path, \"wb\"))\n",
    "        masked_processed_img.save(processed_img_path)\n",
    "        unmasked_processed_img.save(processed_unmasked_img_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T21:46:31.922598Z",
     "start_time": "2020-10-09T21:46:31.887906Z"
    }
   },
   "outputs": [],
   "source": [
    "#pprint.pprint(pickle.load(open(iou_dict_path, \"rb\")))\n",
    "#pprint.pprint(pickle.load(open(pose_dict_path, \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T05:34:02.493526Z",
     "start_time": "2020-10-10T05:31:26.074797Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert rgba images to rgb\n",
    "rgba_img_paths = glob.glob(os.path.join(processed_class_output_dir, \"*.png\"))\n",
    "for rgba_img_path in tqdm(rgba_img_paths):\n",
    "    rgb_img_path = rgba_img_path.replace(\"rgba\", \"rgb\").replace(\".png\", \".jpg\")\n",
    "    rgba_img = Image.open(rgba_img_path)\n",
    "    background = Image.new('RGBA', rgba_img.size, (255,255,255))\n",
    "    rgb_img = Image.alpha_composite(background, rgba_img)\n",
    "    rgb_img = rgb_img.convert(\"RGB\")\n",
    "    rgb_img.save(rgb_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:12:39.199563Z",
     "start_time": "2020-10-10T07:03:04.633078Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a copy of processed pix3d dataset filtered by high quality iou\n",
    "iou_thresh = 0.7\n",
    "PROCESSED_FILTERED_PIX3D_PATH = PROCESSED_PIX3D_PATH + \"_filtered\"\n",
    "\n",
    "#pix3d_classes = [\"tool\"]\n",
    "pix3d_classes = [\"bed\",  \"bookcase\",  \"chair\",  \"desk\",  \"misc\",  \"sofa\",  \"table\",  \"tool\",  \"wardrobe\"]\n",
    "for pix3d_class in tqdm(pix3d_classes):\n",
    "    processed_class_output_dir = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class, \"rgba\")\n",
    "    processed_class_output_dir_rgb = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class, \"rgb\")\n",
    "\n",
    "    processed_filtered_class_output_dir = os.path.join(PROCESSED_FILTERED_PIX3D_PATH, pix3d_class, \"rgba\")\n",
    "    processed_filtered_class_output_dir_rgb = os.path.join(PROCESSED_FILTERED_PIX3D_PATH, pix3d_class, \"rgb\")\n",
    "    if not os.path.exists(processed_filtered_class_output_dir):\n",
    "        os.makedirs(processed_filtered_class_output_dir)\n",
    "    if not os.path.exists(processed_filtered_class_output_dir_rgb):\n",
    "        os.makedirs(processed_filtered_class_output_dir_rgb)\n",
    "    \n",
    "    processed_class_output_dir = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class, \"rgba\")\n",
    "    iou_dict_path = os.path.join(processed_class_output_dir, \"iou_info.pt\")\n",
    "\n",
    "    iou_dict = pickle.load(open(iou_dict_path, \"rb\"))\n",
    "    iou_df = pd.DataFrame.from_dict(iou_dict.items())\n",
    "    iou_df_thresh = iou_df[iou_df[1]>iou_thresh]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "    fig.show()\n",
    "    iou_df.hist(bins=50, ax=axes)\n",
    "    fig.suptitle(pix3d_class)\n",
    "    print(\"{}: {} -> {}\".format(pix3d_class, len(iou_df), len(iou_df_thresh)))\n",
    "    \n",
    "    high_quality_instances = iou_df_thresh[0].to_list()\n",
    "    \n",
    "    original_iou_info = pickle.load(open(os.path.join(processed_class_output_dir, \"iou_info.pt\"), \"rb\"))\n",
    "    filtered_iou_info = {instance:original_iou_info[instance] for instance in original_iou_info if instance in high_quality_instances}\n",
    "    pickle.dump(filtered_iou_info, open(os.path.join(processed_filtered_class_output_dir, \"iou_info.pt\"), \"wb\"))\n",
    "    \n",
    "    original_cameras_info = pickle.load(open(os.path.join(processed_class_output_dir, \"renders_camera_params.pt\"), \"rb\"))\n",
    "    filtered_cameras_info = {instance:original_cameras_info[instance] for instance in original_cameras_info if instance in high_quality_instances}\n",
    "    pickle.dump(filtered_cameras_info, open(os.path.join(processed_filtered_class_output_dir, \"renders_camera_params.pt\"), \"wb\"))\n",
    "    \n",
    "    for high_quality_instance in tqdm(high_quality_instances):\n",
    "        original_instance_path = os.path.join(processed_class_output_dir, \"{}.png\".format(high_quality_instance))\n",
    "        original_instance_path_rgb = os.path.join(processed_class_output_dir_rgb, \"{}.jpg\".format(high_quality_instance))\n",
    "        \n",
    "        dest_instance_path = os.path.join(processed_filtered_class_output_dir, \"{}.png\".format(high_quality_instance))\n",
    "        dest_instance_path_rgb = os.path.join(processed_filtered_class_output_dir_rgb, \"{}.jpg\".format(high_quality_instance))\n",
    "        \n",
    "        #print(original_instance_path, original_instance_path_rgb)\n",
    "        #print(dest_instance_path, dest_instance_path_rgb)\n",
    "        shutil.copyfile(original_instance_path, dest_instance_path)\n",
    "        shutil.copyfile(original_instance_path_rgb, dest_instance_path_rgb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:01:22.154615Z",
     "start_time": "2020-10-10T07:01:21.982709Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(pickle.load(open(os.path.join(processed_filtered_class_output_dir, \"iou_info.pt\"), \"rb\")))\n",
    "print(os.path.join(processed_filtered_class_output_dir, \"iou_info.pt\"))\n",
    "\n",
    "display(pickle.load(open(os.path.join(processed_filtered_class_output_dir, \"renders_camera_params.pt\"), \"rb\")))\n",
    "print(os.path.join(processed_filtered_class_output_dir, \"renders_camera_params.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T23:23:30.056584Z",
     "start_time": "2020-10-11T23:23:25.808598Z"
    }
   },
   "outputs": [],
   "source": [
    "# correct some issues in the renders_camera_params file: 1) turns everything into floats, 2) subtracts azim by 90\n",
    "pix3d_img_folder_to_fix = \"data/input_images/pix3d_images_processed\"\n",
    "camera_params_paths = [str(path) for path in list(Path(pix3d_img_folder_to_fix).rglob('renders_camera_params.pt'))]\n",
    "for camera_params_path in camera_params_paths:\n",
    "    shutil.copyfile(camera_params_path, camera_params_path.replace(\"renders_camera_params\", \"original_renders_camera_params\"))\n",
    "    original_camera_params = pickle.load(open(camera_params_path, \"rb\"))\n",
    "    fixed_camera_params = {}\n",
    "    for instance in original_camera_params:\n",
    "        fixed_camera_params[instance] = {'azim': float(original_camera_params[instance]['azim'])-90, 'dist': float(original_camera_params[instance]['dist']), 'elev': float(original_camera_params[instance]['elev'])}\n",
    "    \n",
    "    pickle.dump(fixed_camera_params, open(camera_params_path, \"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T12:57:21.085293Z",
     "start_time": "2020-10-10T12:57:20.750173Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(pickle.load(open(\"data/pix3d_images_processed_filtered/tool/rgba/renders_camera_params-Copy1.pt\", \"rb\")))\n",
    "#pprint.pprint(pickle.load(open(\"data/pix3d_images_processed_filtered/tool/rgba/renders_camera_params.pt\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
