{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T03:18:27.751167Z",
     "start_time": "2020-10-18T03:18:27.749027Z"
    }
   },
   "outputs": [],
   "source": [
    "# since pix2mesh reconstructs meshes in the pose to the input view, this realignes the models to a class-canonical alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T12:16:08.932394Z",
     "start_time": "2020-10-18T12:16:08.917497Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T12:16:08.944358Z",
     "start_time": "2020-10-18T12:16:08.934150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T12:16:11.065016Z",
     "start_time": "2020-10-18T12:16:08.946380Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pytorch3d\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.io import save_obj\n",
    "from pytorch3d.renderer.cameras import look_at_view_transform\n",
    "from pytorch3d.renderer import Textures\n",
    "\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T03:18:29.423168Z",
     "start_time": "2020-10-18T03:18:29.404419Z"
    }
   },
   "outputs": [],
   "source": [
    "# test pytorch3d \n",
    "#test_mesh_path = \"data/refinements/shapenet_occnet_refinements/gt_pose/02691156/batch_1_of_2/d18592d9615b01bbbc0909d98a1ff2b4.obj\"\n",
    "#test_mesh = utils.load_untextured_mesh(test_mesh_path, device)\n",
    "#test_dist = 1\n",
    "#test_elev = 10\n",
    "#test_azim = 40\n",
    "#test_R, test_T = look_at_view_transform(dist=test_dist, elev=test_elev, azim=test_azim)\n",
    "#m = torch.tensor([[-1,0,0],\n",
    "#                  [0,1,0],\n",
    "#                  [0,0,-1]], dtype=torch.float)\n",
    "#R_adjusted = test_R[0]@m\n",
    "#save_obj(\"test_mesh_out.obj\", test_mesh.verts_packed()@R_adjusted@R_adjusted.T, test_mesh.faces_packed())\n",
    "#test_render = utils.render_mesh(test_mesh, test_R, test_T, device)\n",
    "#plt.imshow(test_render[0,...,:3].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T12:16:11.110602Z",
     "start_time": "2020-10-18T12:16:11.067005Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def center_points(points):\n",
    "    return points - torch.mean(points, 0)\n",
    "\n",
    "def rot_x(theta, degrees=True):\n",
    "    if degrees:\n",
    "        theta = theta * (np.pi/180)\n",
    "    rot_matrix = np.array([[1, 0, 0],\n",
    "                           [0, np.cos(theta), -np.sin(theta)],\n",
    "                           [0, np.sin(theta), np.cos(theta)]\n",
    "                          ])\n",
    "    return rot_matrix\n",
    "\n",
    "def rot_y(theta, degrees=True):\n",
    "    if degrees:\n",
    "        theta = theta * (np.pi/180)\n",
    "    rot_matrix = np.array([[np.cos(theta), 0, np.sin(theta)],\n",
    "                           [0,1,0],\n",
    "                           [-np.sin(theta), 0, np.cos(theta)]\n",
    "                          ])\n",
    "    return rot_matrix\n",
    "\n",
    "def rot_z(theta, degrees=True):\n",
    "    if degrees:\n",
    "        theta = theta * (np.pi/180)\n",
    "    rot_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                           [np.sin(theta), np.cos(theta), 0],\n",
    "                           [0,0,1]\n",
    "                          ])\n",
    "    return rot_matrix\n",
    "\n",
    "def get_mask_iou(render1_mask, render2_mask):\n",
    "    intersection = torch.logical_and(render1_mask, render2_mask)\n",
    "    union = torch.logical_or(render1_mask, render2_mask)\n",
    "    IOU = torch.sum(intersection, dtype=torch.float) / torch.sum(union, dtype=torch.float)\n",
    "    return IOU.item()\n",
    "\n",
    "# rotates a mesh around the x-axis, finding the rotation matrix which causes it to be most \"flat\", and applying that to the input mesh\n",
    "def make_flat(input_mesh, device, min_rot=-20, max_rot=20, num_rot=20):\n",
    "    R, T = look_at_view_transform(dist=0.7, elev=0, azim=90)\n",
    "    verts_rgb = torch.ones_like(input_mesh.verts_packed())[None] # (1, V, 3)\n",
    "    textures = Textures(verts_rgb=verts_rgb)\n",
    "    \n",
    "    highest_iou = None\n",
    "    flattest_mesh = None\n",
    "    for rot_amt in np.linspace(min_rot, max_rot, num=num_rot):\n",
    "        #rotated_verts = input_mesh.verts_packed()@rot_x(rot_amt)\n",
    "        rotated_verts = input_mesh.verts_packed()@torch.tensor(rot_x(rot_amt), dtype=torch.float)\n",
    "        rotated_mesh = pytorch3d.structures.Meshes(verts=rotated_verts.unsqueeze(0), faces=mesh.faces_padded(), textures=textures).to(device)\n",
    "        rotated_render = utils.render_mesh(rotated_mesh, R, T, device)\n",
    "        #plt.imshow(rotated_render[0,...,:3].detach().cpu().numpy())\n",
    "        #plt.show()\n",
    "        #plt.imshow(torch.flip(rotated_render[0,...,:3], [1]).detach().cpu().numpy())\n",
    "        #plt.show()\n",
    "        iou = get_mask_iou(rotated_render[0,...,3]>0, torch.flip(rotated_render[0,...,3], [1])>0)\n",
    "        if highest_iou is None or iou > highest_iou:\n",
    "            highest_iou = iou\n",
    "            flattest_mesh = rotated_mesh\n",
    "        \n",
    "    return flattest_mesh\n",
    "\n",
    "def normalize_pointclouds(points):\n",
    "    max_vert_values = torch.max(points, 0).values\n",
    "    min_vert_values = torch.min(points, 0).values\n",
    "    max_width = torch.max(max_vert_values-min_vert_values)\n",
    "    normalized_points = points * (1/max_width)\n",
    "\n",
    "    return normalized_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T12:16:17.424215Z",
     "start_time": "2020-10-18T12:16:17.397795Z"
    }
   },
   "outputs": [],
   "source": [
    "class_ids = [\"04401088\", \"04530566\"]\n",
    "#class_ids = [\"02691156\", \"02828884\", \"02933112\", \"02958343\", \"03001627\", \"03211117\", \"03636649\", \"03691459\", \"04090263\", \"04256520\", \"04379243\", \"04401088\", \"04530566\"]\n",
    "#class_ids = [\"02828884\", \"02933112\", \"02958343\", \"03001627\", \"03211117\", \"03636649\", \"03691459\", \"04090263\", \"04256520\", \"04379243\", \"04401088\", \"04530566\"]\n",
    "#class_ids=[\"test\"]\n",
    "device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "pix2mesh_rec_dir = \"/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders\"\n",
    "\n",
    "#meshes_dir= \"/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/testt\"\n",
    "#class_pose_dict_path = \"/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders/02691156/rgba/renders_camera_params.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T12:33:44.321422Z",
     "start_time": "2020-10-18T12:16:23.984617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04401088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6aea98331c4c2797844b5a294d3361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "04530566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4098665c45cf4951bed4b5e922fb35ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_ids:\n",
    "    meshes_dir = os.path.join(pix2mesh_rec_dir, class_name)\n",
    "    class_pose_dict_path = os.path.join(meshes_dir, \"rgba\", \"renders_camera_params.pt\")\n",
    "    mesh_paths = [str(path) for path in Path(meshes_dir).rglob(\"*.obj\")]\n",
    "    pose_dict = pickle.load(open(class_pose_dict_path, \"rb\"))\n",
    "    print(class_name)\n",
    "    \n",
    "    for mesh_path in tqdm(mesh_paths):\n",
    "        if \"_aligned\" not in mesh_path:\n",
    "            with torch.no_grad():\n",
    "                mesh = utils.load_untextured_mesh(mesh_path, cpu_device)\n",
    "                instance = mesh_path.split('/')[-1].replace(\".obj\",\"\")\n",
    "                pose = pose_dict[instance]\n",
    "                R, T = look_at_view_transform(dist=pose[\"dist\"], elev=pose[\"elev\"], azim=pose[\"azim\"])\n",
    "                m = torch.tensor([[-1,0,0],\n",
    "                          [0,1,0],\n",
    "                          [0,0,-1]], dtype=torch.float)\n",
    "                R_adjusted = R[0]@m\n",
    "\n",
    "                partially_aligned_verts = center_points(mesh.verts_packed())\n",
    "                partially_aligned_verts = partially_aligned_verts @ R_adjusted.T\n",
    "                partially_aligned_mesh = pytorch3d.structures.Meshes(verts=partially_aligned_verts.unsqueeze(0), faces=mesh.faces_padded())\n",
    "                aligned_mesh = make_flat(partially_aligned_mesh, device)\n",
    "                \n",
    "\n",
    "                #aligned_verts = aligned_verts @ torch.tensor(rot_y(-pose[\"azim\"]), dtype=torch.float, device=device)\n",
    "                #aligned_verts = aligned_verts @ torch.tensor(rot_x(-pose[\"elev\"]), dtype=torch.float, device=device)\n",
    "                #aligned_verts = aligned_verts @ torch.tensor(rot_x(45), dtype=torch.float, device=device)\n",
    "\n",
    "                save_obj(mesh_path, normalize_pointclouds(aligned_mesh.verts_packed()), mesh.faces_packed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
