{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:13.107256Z",
     "start_time": "2020-10-10T00:46:13.092038Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:13.846271Z",
     "start_time": "2020-10-10T00:46:13.835033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:19.928126Z",
     "start_time": "2020-10-10T00:46:14.962604Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "import pytorch3d.transforms\n",
    "import PIL\n",
    "from scipy import ndimage\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import postprocess_dataset\n",
    "from utils import utils\n",
    "from utils import visualization_tools\n",
    "from utils.eval_utils import eval_metrics\n",
    "from utils.brute_force_pose_est import brute_force_estimate_pose, brute_force_estimate_dist, brute_force_estimate_dist_cam_pos, rgba_obj_in_frame\n",
    "#from evaluation import compute_iou_2d, compute_iou_2d_given_pose, compute_iou_3d, compute_chamfer_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:19.964630Z",
     "start_time": "2020-10-10T00:46:19.930575Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# reverse engineered from \n",
    "# https://pytorch3d.readthedocs.io/en/latest/_modules/pytorch3d/renderer/cameras.html#camera_position_from_spherical_angles\n",
    "def cart_to_spherical(cart_coords):\n",
    "    x = cart_coords[0]\n",
    "    y = cart_coords[1]\n",
    "    z = cart_coords[2]\n",
    "    \n",
    "    dist = np.sqrt(x**2 + y**2 + z**2)\n",
    "    elev = np.arcsin(y)/dist\n",
    "    #azim = np.arctan(x/z)\n",
    "    azim = np.arctan(x/z) + np.pi\n",
    "    return dist, elev, azim\n",
    "    \n",
    "def spherical_to_cart(dist, elev, azim):\n",
    "    x = dist * np.cos(elev) * np.sin(azim)\n",
    "    y = dist * np.sin(elev)\n",
    "    z = dist * np.cos(elev) * np.cos(azim)\n",
    "    print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:20.002487Z",
     "start_time": "2020-10-10T00:46:19.967177Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# assumes cam_pos is a vector of numbers\n",
    "def find_best_fitting_cam_pos(mesh, cam_pos, num_dists, device, batch_size=8):\n",
    "    # normalizing\n",
    "    with torch.no_grad():\n",
    "        eyes = [cam_pos*i for i in np.geomspace(0.005, 2, num_dists)]\n",
    "        R, T = look_at_view_transform(eye=eyes)\n",
    "        meshes = mesh.extend(num_dists)\n",
    "        renders = utils.render_mesh(meshes, R, T, device)\n",
    "        \n",
    "        rendered_image_fits = []\n",
    "        for i in range(renders.shape[0]):\n",
    "            rendered_image_fits.append(rgba_obj_in_frame(renders[i].cpu().numpy()))\n",
    "\n",
    "        # choose closest cam_pos, whose rendered image will fit completely in the frame\n",
    "        i = 0\n",
    "        while not rendered_image_fits[i]:\n",
    "            i+=1\n",
    "\n",
    "        best_cam_pos = eyes[i]\n",
    "        \n",
    "    return best_cam_pos\n",
    "\n",
    "def get_iou(mask1, mask2):\n",
    "    intersect = mask1 * mask2 # Logical AND\n",
    "    union = mask1 + mask2 # Logical OR\n",
    "    IOU = intersect.sum()/float(union.sum())\n",
    "    return IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:20.053492Z",
     "start_time": "2020-10-10T00:46:20.004755Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_pix3d_image(curr_info_dict, visualize=False, inplane=True, use_spherical=True):\n",
    "    #pprint.pprint(curr_info_dict)\n",
    "    img_path = os.path.join(PIX3D_PATH, curr_info_dict[\"img\"])\n",
    "    mesh_path = os.path.join(PIX3D_PATH, curr_info_dict[\"model\"])\n",
    "    mask_path = os.path.join(PIX3D_PATH, curr_info_dict[\"mask\"])\n",
    "    cam_pos = curr_info_dict[\"cam_position\"]\n",
    "    theta = curr_info_dict[\"inplane_rotation\"]\n",
    "    img = Image.open(img_path)\n",
    "    mesh = utils.load_untextured_mesh(mesh_path, device)\n",
    "\n",
    "    up_axis = [0,1,0] \n",
    "    if inplane:\n",
    "        theta = curr_info_dict[\"inplane_rotation\"]\n",
    "        inplane_R = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta),0],[0,0,1]])\n",
    "        up_axis = (inplane_R@np.array([up_axis]).T).T[0]\n",
    "\n",
    "    # obtaining GT pose in spherical coordinates\n",
    "    cam_pos = np.array(cam_pos)/np.sqrt(cam_pos[0]**2+cam_pos[1]**2+cam_pos[2]**2)\n",
    "    dist, elev, azim = cart_to_spherical(cam_pos)\n",
    "    azim = azim * (180/np.pi) \n",
    "    elev = elev * (180/np.pi) \n",
    "    R, T = look_at_view_transform(dist,elev,azim, up=[up_axis])\n",
    "    spherical_based_render = utils.render_mesh(mesh, R, T, device, img_size=img_size)\n",
    "\n",
    "    # double checking spherical coordinates conversion to see it it matches camera position based pose\n",
    "    # Note sure why this is necessary\n",
    "    R, T = look_at_view_transform(eye=[cam_pos], up=[up_axis])\n",
    "    cam_based_render = utils.render_mesh(mesh, R, T, device, img_size=img_size)\n",
    "    render_comparision_iou = get_iou(spherical_based_render[0,...,3]>0, cam_based_render[0,...,3]>0)\n",
    "    flipped=False\n",
    "    if render_comparision_iou.item() < 0.95:\n",
    "        azim += 180\n",
    "        R, T = look_at_view_transform(dist,elev,azim, up=[up_axis])\n",
    "        spherical_based_render = utils.render_mesh(mesh, R, T, device, img_size=img_size)\n",
    "        flipped=True\n",
    "    \n",
    "    mask = Image.open(mask_path)\n",
    "    mask_bbox = curr_info_dict[\"bbox\"]\n",
    "    img_masked_rgba = Image.composite(Image.new(\"RGBA\", curr_info_dict['img_size']), img.convert('RGBA'), PIL.ImageOps.invert(mask))\n",
    "    img_masked_rgba = img_masked_rgba.crop(mask_bbox)\n",
    "\n",
    "    objs = ndimage.find_objects(spherical_based_render[0,...,3].detach().cpu().numpy()>0.2)\n",
    "    # upper left, lower right\n",
    "    #render_bbox = [objs[0][0].start, objs[0][1].start, objs[0][0].stop, objs[0][1].stop]\n",
    "    render_bbox = [objs[0][1].start, objs[0][0].start, objs[0][1].stop, objs[0][0].stop]\n",
    "    render_bbox_width = render_bbox[2] - render_bbox[0]\n",
    "    render_bbox_height = render_bbox[3] - render_bbox[1]\n",
    "    img_masked_rgba_resized = img_masked_rgba.resize((render_bbox_width, render_bbox_height))\n",
    "    processed_img = Image.new(\"RGBA\", (img_size, img_size))\n",
    "    processed_img.paste(img_masked_rgba_resized, box=render_bbox[:2])\n",
    "\n",
    "    final_iou = get_iou(spherical_based_render[0, ..., 3].detach().cpu().numpy() > 0, np.array(processed_img)[...,3]>0)\n",
    "    if visualize:\n",
    "        plt.imshow(img_masked_rgba)\n",
    "        plt.show()\n",
    "        plt.imshow(spherical_based_render[0, ..., :3].detach().cpu().numpy())\n",
    "        plt.show()\n",
    "        plt.imshow(processed_img)\n",
    "        plt.show()\n",
    "    return processed_img, dist, elev, azim, final_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:33.388186Z",
     "start_time": "2020-10-10T00:46:33.339108Z"
    }
   },
   "outputs": [],
   "source": [
    "pix3d_class = \"chair\"\n",
    "\n",
    "PIX3D_PATH = \"/home/svcl-oowl/dataset/pix3d\"\n",
    "PROCESSED_PIX3D_PATH = \"data/pix3d_images_processed\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "img_size = 224\n",
    "blacklist = [\"img/table/0045\", \"img/table/1749\"]\n",
    "recompute=False\n",
    "\n",
    "processed_class_output_dir = os.path.join(PROCESSED_PIX3D_PATH, pix3d_class)\n",
    "if not os.path.exists(processed_class_output_dir):\n",
    "    os.makedirs(processed_class_output_dir)\n",
    "pose_dict_path = os.path.join(processed_class_output_dir, \"renders_camera_params.pt\")\n",
    "iou_dict_path = os.path.join(processed_class_output_dir, \"iou_info.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:46:37.129026Z",
     "start_time": "2020-10-10T00:46:35.927091Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PIX3D_PATH, \"pix3d.json\")) as f:\n",
    "    pix3d_data_json = json.loads(f.read())\n",
    "# convert list of dicts into a dict (keyed by image path) of dicts\n",
    "pix3d_data_dict = { entry[\"img\"].split('.')[0]:entry for entry in pix3d_data_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T02:58:15.946574Z",
     "start_time": "2020-10-10T00:46:39.422602Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00eefed6f4514da7b621d168e2eae9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3839.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/chair/1151\n",
      "img/chair/1152\n",
      "img/chair/1153\n",
      "img/chair/1154\n",
      "img/chair/1155\n",
      "img/chair/1156\n",
      "img/chair/1157\n",
      "img/chair/1158\n",
      "img/chair/1159\n",
      "img/chair/1160\n",
      "img/chair/1161\n",
      "img/chair/1162\n",
      "img/chair/1163\n",
      "img/chair/1164\n",
      "img/chair/1165\n",
      "img/chair/1166\n",
      "img/chair/1167\n",
      "img/chair/1168\n",
      "img/chair/1169\n",
      "img/chair/1170\n",
      "img/chair/1171\n",
      "img/chair/1172\n",
      "img/chair/1173\n",
      "img/chair/1174\n",
      "img/chair/1175\n",
      "img/chair/1176\n",
      "img/chair/1177\n",
      "img/chair/1178\n",
      "img/chair/1179\n",
      "img/chair/1180\n",
      "img/chair/1181\n",
      "img/chair/1182\n",
      "img/chair/1183\n",
      "img/chair/1184\n",
      "img/chair/1185\n",
      "img/chair/1186\n",
      "img/chair/1187\n",
      "img/chair/1188\n",
      "img/chair/1189\n",
      "img/chair/1190\n",
      "img/chair/1191\n",
      "img/chair/1192\n",
      "img/chair/1193\n",
      "img/chair/1194\n",
      "img/chair/1195\n",
      "img/chair/1196\n",
      "img/chair/1197\n",
      "img/chair/1198\n",
      "img/chair/1199\n",
      "img/chair/1200\n",
      "img/chair/1201\n",
      "img/chair/1202\n",
      "img/chair/1203\n",
      "img/chair/1204\n",
      "img/chair/1205\n",
      "img/chair/1206\n",
      "img/chair/1207\n",
      "img/chair/1208\n",
      "img/chair/1209\n",
      "img/chair/1210\n",
      "img/chair/1211\n",
      "img/chair/1212\n",
      "img/chair/1213\n",
      "img/chair/1214\n",
      "img/chair/1215\n",
      "img/chair/1216\n",
      "img/chair/1217\n",
      "img/chair/1218\n",
      "img/chair/1219\n",
      "img/chair/1220\n",
      "img/chair/1221\n",
      "img/chair/1222\n",
      "img/chair/1223\n",
      "img/chair/1224\n",
      "img/chair/1225\n",
      "img/chair/1226\n",
      "img/chair/1227\n",
      "img/chair/1228\n",
      "img/chair/1229\n",
      "img/chair/1230\n",
      "img/chair/1231\n",
      "img/chair/1232\n",
      "img/chair/1233\n",
      "img/chair/1234\n",
      "img/chair/1235\n",
      "img/chair/1236\n",
      "img/chair/1237\n",
      "img/chair/1238\n",
      "img/chair/1239\n",
      "img/chair/1240\n",
      "img/chair/1241\n",
      "img/chair/1242\n",
      "img/chair/1243\n",
      "img/chair/1244\n",
      "img/chair/1245\n",
      "img/chair/1246\n",
      "img/chair/1247\n",
      "img/chair/1248\n",
      "img/chair/1249\n",
      "img/chair/1250\n",
      "img/chair/1251\n",
      "img/chair/1252\n",
      "img/chair/1253\n",
      "img/chair/1254\n",
      "img/chair/1255\n",
      "img/chair/1256\n",
      "img/chair/1257\n",
      "img/chair/1258\n",
      "img/chair/1259\n",
      "img/chair/1260\n",
      "img/chair/1261\n",
      "img/chair/1262\n",
      "img/chair/1263\n",
      "img/chair/1264\n",
      "img/chair/1265\n",
      "img/chair/1266\n",
      "img/chair/1267\n",
      "img/chair/1268\n",
      "img/chair/1269\n",
      "img/chair/1270\n",
      "img/chair/1271\n",
      "img/chair/1272\n",
      "img/chair/1273\n",
      "img/chair/1274\n",
      "img/chair/1275\n",
      "img/chair/1276\n",
      "img/chair/1277\n",
      "img/chair/1278\n",
      "img/chair/1279\n",
      "img/chair/1280\n",
      "img/chair/1281\n",
      "img/chair/1282\n",
      "img/chair/1283\n",
      "img/chair/1284\n",
      "img/chair/1285\n",
      "img/chair/1286\n",
      "img/chair/1287\n",
      "img/chair/1288\n",
      "img/chair/1289\n",
      "img/chair/1290\n",
      "img/chair/1291\n",
      "img/chair/1292\n",
      "img/chair/1293\n",
      "img/chair/1294\n",
      "img/chair/1295\n",
      "img/chair/1296\n",
      "img/chair/1297\n",
      "img/chair/1298\n",
      "img/chair/1299\n",
      "img/chair/1300\n",
      "img/chair/1301\n",
      "img/chair/1302\n",
      "img/chair/1303\n",
      "img/chair/1304\n",
      "img/chair/1305\n",
      "img/chair/1306\n",
      "img/chair/1307\n",
      "img/chair/1308\n",
      "img/chair/1309\n",
      "img/chair/1310\n",
      "img/chair/1311\n",
      "img/chair/1312\n",
      "img/chair/1313\n",
      "img/chair/1314\n",
      "img/chair/1315\n",
      "img/chair/1316\n",
      "img/chair/1317\n",
      "img/chair/1318\n",
      "img/chair/1319\n",
      "img/chair/1320\n",
      "img/chair/1321\n",
      "img/chair/1322\n",
      "img/chair/1323\n",
      "img/chair/1324\n",
      "img/chair/1325\n",
      "img/chair/1326\n",
      "img/chair/1327\n",
      "img/chair/1328\n",
      "img/chair/1329\n",
      "img/chair/1330\n",
      "img/chair/1331\n",
      "img/chair/1332\n",
      "img/chair/1333\n",
      "img/chair/1334\n",
      "img/chair/1335\n",
      "img/chair/1336\n",
      "img/chair/1337\n",
      "img/chair/1338\n",
      "img/chair/1339\n",
      "img/chair/1340\n",
      "img/chair/1341\n",
      "img/chair/1342\n",
      "img/chair/1343\n",
      "img/chair/1344\n",
      "img/chair/1345\n",
      "img/chair/1346\n",
      "img/chair/1347\n",
      "img/chair/1348\n",
      "img/chair/1349\n",
      "img/chair/1350\n",
      "img/chair/1351\n",
      "img/chair/1352\n",
      "img/chair/1353\n",
      "img/chair/1354\n",
      "img/chair/1355\n",
      "img/chair/1356\n",
      "img/chair/1357\n",
      "img/chair/1358\n",
      "img/chair/1359\n",
      "img/chair/1360\n",
      "img/chair/1361\n",
      "img/chair/1362\n",
      "img/chair/1363\n",
      "img/chair/1364\n",
      "img/chair/1365\n",
      "img/chair/1366\n",
      "img/chair/1367\n",
      "img/chair/1368\n",
      "img/chair/1369\n",
      "img/chair/1370\n",
      "img/chair/1371\n",
      "img/chair/1372\n",
      "img/chair/1373\n",
      "img/chair/1374\n",
      "img/chair/1375\n",
      "img/chair/1376\n",
      "img/chair/1377\n",
      "img/chair/1378\n",
      "img/chair/1379\n",
      "img/chair/1380\n",
      "img/chair/1381\n",
      "img/chair/1382\n",
      "img/chair/1383\n",
      "img/chair/1384\n",
      "img/chair/1385\n",
      "img/chair/1386\n",
      "img/chair/1387\n",
      "img/chair/1388\n",
      "img/chair/1389\n",
      "img/chair/1390\n",
      "img/chair/1391\n",
      "img/chair/1392\n",
      "img/chair/1393\n",
      "img/chair/1394\n",
      "img/chair/1395\n",
      "img/chair/1396\n",
      "img/chair/1397\n",
      "img/chair/1398\n",
      "img/chair/1399\n",
      "img/chair/1400\n",
      "img/chair/1401\n",
      "img/chair/1402\n",
      "img/chair/1403\n",
      "img/chair/1404\n",
      "img/chair/1405\n",
      "img/chair/1406\n",
      "img/chair/1407\n",
      "img/chair/1408\n",
      "img/chair/1409\n",
      "img/chair/1410\n",
      "img/chair/1411\n",
      "img/chair/1412\n",
      "img/chair/1413\n",
      "img/chair/1414\n",
      "img/chair/1415\n",
      "img/chair/1416\n",
      "img/chair/1417\n",
      "img/chair/1418\n",
      "img/chair/1419\n",
      "img/chair/1420\n",
      "img/chair/1421\n",
      "img/chair/1422\n",
      "img/chair/1423\n",
      "img/chair/1424\n",
      "img/chair/1425\n",
      "img/chair/1426\n",
      "img/chair/1427\n",
      "img/chair/1428\n",
      "img/chair/1429\n",
      "img/chair/1430\n",
      "img/chair/1431\n",
      "img/chair/1432\n",
      "img/chair/1433\n",
      "img/chair/1434\n",
      "img/chair/1435\n",
      "img/chair/1436\n",
      "img/chair/1437\n",
      "img/chair/1438\n",
      "img/chair/1439\n",
      "img/chair/1440\n",
      "img/chair/1441\n",
      "img/chair/1442\n",
      "img/chair/1443\n",
      "img/chair/1444\n",
      "img/chair/1445\n",
      "img/chair/1446\n",
      "img/chair/1447\n",
      "img/chair/1448\n",
      "img/chair/1449\n",
      "img/chair/1450\n",
      "img/chair/1451\n",
      "img/chair/1452\n",
      "img/chair/1453\n",
      "img/chair/1454\n",
      "img/chair/1455\n",
      "img/chair/1456\n",
      "img/chair/1457\n",
      "img/chair/1458\n",
      "img/chair/1459\n",
      "img/chair/1460\n",
      "img/chair/1461\n",
      "img/chair/1462\n",
      "img/chair/1463\n",
      "img/chair/1464\n",
      "img/chair/1465\n",
      "img/chair/1466\n",
      "img/chair/1467\n",
      "img/chair/1468\n",
      "img/chair/1469\n",
      "img/chair/1470\n",
      "img/chair/1471\n",
      "img/chair/1472\n",
      "img/chair/1473\n",
      "img/chair/1474\n",
      "img/chair/1475\n",
      "img/chair/1476\n",
      "img/chair/1477\n",
      "img/chair/1478\n",
      "img/chair/1479\n",
      "img/chair/1480\n",
      "img/chair/1481\n",
      "img/chair/1482\n",
      "img/chair/1483\n",
      "img/chair/1484\n",
      "img/chair/1485\n",
      "img/chair/1486\n",
      "img/chair/1487\n",
      "img/chair/1488\n",
      "img/chair/1489\n",
      "img/chair/1490\n",
      "img/chair/1491\n",
      "img/chair/1492\n",
      "img/chair/1493\n",
      "img/chair/1494\n",
      "img/chair/1495\n",
      "img/chair/1496\n",
      "img/chair/1497\n",
      "img/chair/1498\n",
      "img/chair/1499\n",
      "img/chair/1500\n",
      "img/chair/1501\n",
      "img/chair/1502\n",
      "img/chair/1503\n",
      "img/chair/1504\n",
      "img/chair/1505\n",
      "img/chair/1506\n",
      "img/chair/1507\n",
      "img/chair/1508\n",
      "img/chair/1509\n",
      "img/chair/1510\n",
      "img/chair/1511\n",
      "img/chair/1512\n",
      "img/chair/1513\n",
      "img/chair/1514\n",
      "img/chair/1515\n",
      "img/chair/1516\n",
      "img/chair/1517\n",
      "img/chair/1518\n",
      "img/chair/1519\n",
      "img/chair/1520\n",
      "img/chair/1521\n",
      "img/chair/1522\n",
      "img/chair/1523\n",
      "img/chair/1524\n",
      "img/chair/1525\n",
      "img/chair/1526\n",
      "img/chair/1527\n",
      "img/chair/1528\n",
      "img/chair/1529\n",
      "img/chair/1530\n",
      "img/chair/1531\n",
      "img/chair/1532\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3dae1fe982ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstance_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblacklist\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrecompute\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprocessed_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_pix3d_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpix3d_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0miou_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance_class_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpose_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance_class_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"azim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mazim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"elev\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0melev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dist\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-42a9ac9e80fb>\u001b[0m in \u001b[0;36mprocess_pix3d_image\u001b[0;34m(curr_info_dict, visualize, inplane, use_spherical)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_info_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inplane_rotation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_untextured_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mup_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/svcl-oowl/brandon/research/sil_consistent_at_inference/utils/utils.py\u001b[0m in \u001b[0;36mload_untextured_mesh\u001b[0;34m(mesh_path, device)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_untextured_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_objs_as_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_textures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaces_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverts_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mverts_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (1, V, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/standard/lib/python3.6/site-packages/pytorch3d/io/obj_io.py\u001b[0m in \u001b[0;36mload_obj\u001b[0;34m(f, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mtexture_atlas_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexture_atlas_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mtexture_wrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexture_wrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/standard/lib/python3.6/site-packages/pytorch3d/io/obj_io.py\u001b[0m in \u001b[0;36m_load_obj\u001b[0;34m(f_obj, data_dir, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, device)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_textures_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         faces_textures_idx = _format_faces_indices(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mfaces_textures_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts_uvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_materials_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/standard/lib/python3.6/site-packages/pytorch3d/io/obj_io.py\u001b[0m in \u001b[0;36m_format_faces_indices\u001b[0;34m(faces_indices, max_index, device, pad_value)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpad_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfaces_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_check_faces_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(pose_dict_path):\n",
    "    pose_dict = pickle.load(open(pose_dict_path, \"rb\"))\n",
    "else:\n",
    "    pose_dict = {}\n",
    "    \n",
    "if os.path.exists(iou_dict_path):\n",
    "    iou_dict = pickle.load(open(iou_dict_path, \"rb\"))\n",
    "else:\n",
    "    iou_dict = {}\n",
    "\n",
    "class_instance_names = [instance_name for instance_name in pix3d_data_dict.keys() if pix3d_class in instance_name]\n",
    "for instance_name in tqdm(class_instance_names):\n",
    "    instance_class_id = instance_name.split('/')[-1]\n",
    "    processed_img_path = os.path.join(processed_class_output_dir, \"{}.png\".format(instance_class_id))\n",
    "    if instance_name not in blacklist and (recompute or not os.path.exists(processed_img_path)):\n",
    "        print(instance_name)\n",
    "        processed_img, dist, elev, azim, iou = process_pix3d_image(pix3d_data_dict[instance_name], visualize=False)\n",
    "        iou_dict[instance_class_id] = iou\n",
    "        pose_dict[instance_class_id] = {\"azim\": azim, \"elev\": elev, \"dist\": dist}\n",
    "        pickle.dump(iou_dict, open(iou_dict_path, \"wb\"))\n",
    "        pickle.dump(pose_dict, open(pose_dict_path, \"wb\"))\n",
    "        processed_img.save(processed_img_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T21:46:31.922598Z",
     "start_time": "2020-10-09T21:46:31.887906Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(pickle.load(open(iou_dict_path, \"rb\")))\n",
    "pprint.pprint(pickle.load(open(pose_dict_path, \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
