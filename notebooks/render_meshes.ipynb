{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T10:05:13.499667Z",
     "start_time": "2020-08-19T10:05:13.476713Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T10:05:14.107313Z",
     "start_time": "2020-08-19T10:05:14.097643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T10:05:16.690448Z",
     "start_time": "2020-08-19T10:05:14.904197Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/standard/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T10:05:18.071247Z",
     "start_time": "2020-08-19T10:05:18.047038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will render 40 real images\n"
     ]
    }
   ],
   "source": [
    "# this notebook recursively finds all .objs in the input mesh folder and renders them into the output render folder, as jpgs with white backgrounds\n",
    "# a partition .list file is also generated for the training/validation set\n",
    "\n",
    "#INPUT_MESH_DIR_REAL = \"data/misc/example_shapenet\"\n",
    "INPUT_MESH_DIR_REAL = \"/home/svcl-oowl/dataset/ShapeNetCore.v1/03001627\"\n",
    "OUTPUT_RENDER_DIR_REAL = \"data/semantic_dis/real_renders\"\n",
    "\n",
    "INPUT_MESH_DIR_FAKE = \"data/test_dataset\"\n",
    "OUTPUT_RENDER_DIR_FAKE = \"data/semantic_dis/fake_renders\"\n",
    "\n",
    "render_type = \"real\"\n",
    "num_img_to_render = 8 * 5\n",
    "#num_img_to_render = min(len(list(Path(INPUT_MESH_DIR_REAL).rglob('*.obj'))), len(list(Path(INPUT_MESH_DIR_FAKE).rglob('*.obj')))) * 8\n",
    "print(\"will render {} {} images\".format(num_img_to_render, render_type))\n",
    "val_split_percentage = 0.25\n",
    "\n",
    "# render settings\n",
    "silhouette = True\n",
    "img_size = 224\n",
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 8\n",
    "num_azims = 8\n",
    "# 0.,  45.,  90., 135., 180., 225., 270., 315.\n",
    "azims = torch.linspace(0, 360, num_azims+1)[:-1]\n",
    "elevs = torch.ones(num_azims) * 25\n",
    "dists = torch.ones(num_azims) * 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T10:09:38.895698Z",
     "start_time": "2020-08-19T10:05:25.203170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f494e318e9a54ab78b946670a26d7d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if render_type == \"real\":\n",
    "    OUTPUT_RENDER_DIR = OUTPUT_RENDER_DIR_REAL\n",
    "    INPUT_MESH_DIR = INPUT_MESH_DIR_REAL\n",
    "elif render_type == \"fake\":\n",
    "    OUTPUT_RENDER_DIR = OUTPUT_RENDER_DIR_FAKE\n",
    "    INPUT_MESH_DIR = INPUT_MESH_DIR_FAKE\n",
    "else:\n",
    "    raise Error(\"must be real or fake\")\n",
    "    \n",
    "if not os.path.exists(OUTPUT_RENDER_DIR):\n",
    "    os.makedirs(OUTPUT_RENDER_DIR)\n",
    "    \n",
    "# TODO: randomize?\n",
    "obj_paths = list(Path(INPUT_MESH_DIR).rglob('*.obj'))\n",
    "\n",
    "render_i = 0\n",
    "train_img_names = []\n",
    "val_img_names = []\n",
    "with tqdm(total=num_img_to_render) as pbar:\n",
    "    for model_path in obj_paths:\n",
    "        with torch.no_grad():\n",
    "            mesh = utils.load_untextured_mesh(model_path, device)\n",
    "            renders = utils.batched_render(mesh, azims, elevs, dists, batch_size, device, silhouette, img_size)\n",
    "            curr_renders_names = []\n",
    "            for i, render in enumerate(renders):\n",
    "                \n",
    "                if silhouette:\n",
    "                    # turn into hard 0/1 siluette\n",
    "                    img_render = (render[ ..., 3].cpu().numpy() > 0).astype(int) * 255\n",
    "                else:\n",
    "                    img_render = (render[ ..., :3].cpu().numpy()* 255).astype(int) \n",
    "                    \n",
    "                model_name = str(model_path).replace(INPUT_MESH_DIR,'').replace('/','_').replace(\".obj\",\"\")\n",
    "                if model_name[0] == '_': model_name = model_name[1:]\n",
    "                \n",
    "                render_filename = \"{}_{}.jpg\".format(model_name, i)\n",
    "                cv2.imwrite(os.path.join(OUTPUT_RENDER_DIR,render_filename), img_render)\n",
    "                curr_renders_names.append(render_filename)\n",
    "                #plt.imshow(img_render)\n",
    "                #plt.show()\n",
    "                \n",
    "                pbar.update(1)\n",
    "                render_i += 1\n",
    "            \n",
    "            if render_i < num_img_to_render * val_split_percentage:\n",
    "                val_img_names += curr_renders_names\n",
    "            else:\n",
    "                train_img_names += curr_renders_names\n",
    "                \n",
    "            if render_i >= num_img_to_render:\n",
    "                break\n",
    "\n",
    "# creating .lst files to record train/val partition info\n",
    "with open(os.path.join(OUTPUT_RENDER_DIR, \"train.lst\"), \"w\") as f:\n",
    "    for i, img_name in enumerate(train_img_names):\n",
    "        if i < len(train_img_names)-1:\n",
    "            f.write(img_name+\"\\n\")\n",
    "        else:\n",
    "            f.write(img_name)\n",
    "\n",
    "with open(os.path.join(OUTPUT_RENDER_DIR, \"val.lst\"), \"w\") as f:\n",
    "    for i, img_name in enumerate(val_img_names):\n",
    "        if i < len(val_img_names)-1:\n",
    "            f.write(img_name+\"\\n\")\n",
    "        else:\n",
    "            f.write(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
