{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:29.456969Z",
     "start_time": "2020-10-20T10:21:29.435475Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:30.135528Z",
     "start_time": "2020-10-20T10:21:30.120969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:40.908511Z",
     "start_time": "2020-10-20T10:21:31.028576Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pprint\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from utils import utils\n",
    "from utils import eval_utils\n",
    "import deformation.losses as def_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T00:32:53.964475Z",
     "start_time": "2020-10-11T00:32:53.659161Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# processing pose quality annotations\n",
    "import xmltodict\n",
    "pose_annotation_path = \"notebooks/pix3d_chair_occnet_pose_quality_annotations.xml\"\n",
    "# processing xml from cvat\n",
    "# https://github.com/openvinotoolkit/cvat\n",
    "with open (pose_annotation_path, 'r') as f:\n",
    "    f = f.read()\n",
    "d = dict(xmltodict.parse(f))\n",
    "\n",
    "pose_annotation_dict = {}\n",
    "pose_quality_stats = {\"num_good\":0, \"num_medium\":0, \"num_bad\":0}\n",
    "for entry in d['annotations']['image']:\n",
    "    anno_dict = dict(entry)\n",
    "    entry_label = dict(anno_dict['tag'])['@label']\n",
    "    pose_annotation_dict[anno_dict['@name'].replace('.png', '')] = entry_label\n",
    "    pose_quality_stats[\"num_{}\".format(entry_label)] += 1\n",
    "    \n",
    "pprint.pprint(pose_quality_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T06:14:04.407912Z",
     "start_time": "2020-09-30T06:14:04.384309Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def filter_eval_df_by_quality(original_eval_df, pose_quality_dict, allowed_qualities=[\"good\"]):\n",
    "    instances_to_consider = [instance for instance in pose_quality_dict if pose_quality_dict[instance] in allowed_qualities]    \n",
    "    filtered_df = original_eval_df[original_eval_df[\"instance\"].isin(instances_to_consider)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:40.957823Z",
     "start_time": "2020-10-20T10:21:40.911232Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_before_after_refinement(results_df_before, results_df_after):\n",
    "    \n",
    "    statistics = {\"num_3d_iou_improved\":0, \"avg_improve_amt\": 0, \"avg_improve_before_2d_iou\":0, \"num_3d_iou_worse\":0,  \"avg_worse_amt\":0, \"avg_worse_before_2d_iou\":0}\n",
    "    improved_instances = []\n",
    "    worse_instances = []\n",
    "    comparision_df = pd.DataFrame()\n",
    "    for instance in list(results_df_after[\"instance\"]):\n",
    "        if instance in list(results_df_before[\"instance\"]):\n",
    "            before_result = results_df_before[results_df_before[\"instance\"]==instance]\n",
    "            before_3d_iou = float(before_result[\"3d_iou\"])\n",
    "            #before_2d_iou = float(before_result[\"2d_iou\"])\n",
    "            after_result = results_df_after[results_df_after[\"instance\"]==instance]\n",
    "            after_3d_iou = float(after_result[\"3d_iou\"])\n",
    "            #after_2d_iou = float(after_result[\"2d_iou\"])\n",
    "\n",
    "            #iou_2d_change = after_2d_iou - before_2d_iou\n",
    "            iou_3d_change = after_3d_iou - before_3d_iou\n",
    "\n",
    "            if math.isnan(iou_3d_change):\n",
    "                statistics[\"num_3d_iou_worse\"] += 1\n",
    "                continue\n",
    "            elif iou_3d_change > 0:\n",
    "                statistics[\"num_3d_iou_improved\"] += 1\n",
    "                statistics[\"avg_improve_amt\"] += iou_3d_change\n",
    "                #statistics[\"avg_improve_before_2d_iou\"] += before_2d_iou\n",
    "                improved_instances.append(instance)\n",
    "            else:\n",
    "                statistics[\"num_3d_iou_worse\"] += 1\n",
    "                statistics[\"avg_worse_amt\"] += iou_3d_change\n",
    "                #statistics[\"avg_worse_before_2d_iou\"] += before_2d_iou\n",
    "                worse_instances.append(instance)\n",
    "            comparision_df = comparision_df.append({\"instance\": instance, \"iou_3d_delta\": iou_3d_change}, ignore_index=True)\n",
    "\n",
    "    statistics[\"avg_improve_amt\"] /= statistics[\"num_3d_iou_improved\"]\n",
    "    statistics[\"avg_improve_before_2d_iou\"] /= statistics[\"num_3d_iou_improved\"]\n",
    "    statistics[\"avg_worse_amt\"] /= statistics[\"num_3d_iou_worse\"]\n",
    "    statistics[\"avg_worse_before_2d_iou\"] /= statistics[\"num_3d_iou_worse\"]\n",
    "            \n",
    "    pprint.pprint(statistics)\n",
    "    #print(\"example improved instances\")\n",
    "    #print(improved_instances[:100])\n",
    "    #print(\"example worse instances\")\n",
    "    #print(worse_instances[:100])\n",
    "    return comparision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:41.012143Z",
     "start_time": "2020-10-20T10:21:40.960290Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_eval_df_warnings(original_df, warnings_to_filter=[\"NaN nodes\", \"compute_iou_3d: gt mesh < 200 occupancies\", \"compute_iou_3d: rec mesh < 200 occupancies\"]):\n",
    "    filter_array = []\n",
    "    warnings_list = original_df[\"eval_warnings\"].tolist()\n",
    "    for i in range(len(original_df)):\n",
    "        warnings = warnings_list[i]\n",
    "        keep=True\n",
    "        for warning in warnings:\n",
    "            if warning in warnings_to_filter:\n",
    "                keep=False\n",
    "        filter_array.append(keep)\n",
    "    return original_df[filter_array]\n",
    "\n",
    "def filter_and_sort_eval_dfs(df1, df2):\n",
    "    df1 = filter_eval_df_warnings(df1)\n",
    "    df2 = filter_eval_df_warnings(df2)\n",
    "    df1_instances = df1[\"instance\"].tolist()\n",
    "    df2_instances = df2[\"instance\"].tolist()\n",
    "    \n",
    "    df1_filters = [(True if df1_instance in df2_instances else False) for df1_instance in df1_instances]\n",
    "    df1_filtered = df1[df1_filters].sort_values(by=\"instance\")\n",
    "    \n",
    "    df2_filters = [(True if df2_instance in df1_instances else False) for df2_instance in df2_instances]\n",
    "    df2_filtered = df2[df2_filters].sort_values(by=\"instance\")\n",
    "    \n",
    "    return df1_filtered, df2_filtered\n",
    "\n",
    "def update_2d_iou_input_to_bf(original_df, bf_2d_iou_df):\n",
    "    if (original_df[\"instance\"].tolist() != bf_2d_iou_df[\"instance\"].tolist() ):\n",
    "        raise ValueError(\"Instances don't match\")\n",
    "    original_df[\"2d_iou_input\"] = bf_2d_iou_df[\"2d_iou_input\"]\n",
    "    return original_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:43.898926Z",
     "start_time": "2020-10-20T10:21:43.194853Z"
    }
   },
   "outputs": [],
   "source": [
    "# shapenet\n",
    "#class_ids = [\"02691156\", \"02828884\", \"02933112\", \"02958343\", \"03001627\", \"03211117\", \"03636649\", \"03691459\", \"04090263\", \"04256520\", \"04379243\", \"04401088\", \"04530566\"]\n",
    "class_ids = [\"04090263\"]\n",
    "# pix2mesh\n",
    "evaluation_dir_before_temp = \"/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders/{}/rgba\"\n",
    "evaluation_dir_after_temp = \"data/refinements/shapenet_pix2mesh_refinements/{}_pose/{}\"\n",
    "# occnet\n",
    "#evaluation_dir_before_temp = \"/home/svcl-oowl/brandon/research/occupancy_networks/out/pytorch3d_renders/{}/generation/meshes\"\n",
    "#evaluation_dir_after_temp = \"data/refinements/shapenet_occnet_refinements/{}_pose/{}\"\n",
    "\n",
    "# pix3d\n",
    "#evaluation_dir_before_temp = \"/home/svcl-oowl/brandon/research/occupancy_networks/out/pix3d/{}/generation/meshes\"\n",
    "#evaluation_dir_after_temp = \"data/refinements/pix3d_occnet_refinements/{}_pose/{}\"\n",
    "#class_ids = [\"bed\", \"bookcase\", \"chair\", \"desk\", \"misc\", \"sofa\", \"table\",\"tool\", \"wardrobe\"]\n",
    "\n",
    "pose_type = \"gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T10:21:46.798680Z",
     "start_time": "2020-10-20T10:21:45.100044Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "474\n",
      "474\n",
      "/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders/04090263/rgba -> data/refinements/shapenet_pix2mesh_refinements/gt_pose/04090263\n",
      "Note: filtering results from 474 to 416\n",
      "\n",
      "\n",
      " Delta: \n",
      "\n",
      "2d_iou_input    1.260621\n",
      "2d_iou_multi    1.297079\n",
      "3d_iou          2.315801\n",
      "chamfer_L1      0.482364\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "most improved: ['e42d10c193cce254719aed4531d5366b', 'cf21d9de1440d3d203f35d9b3b48203', 'd2aef97be32d8118433d7c8e9cebd7c2', 'fe286de2443835694aa96bdf46776318', 'd9eede71f6941a7c766069834b8696c7', 'd75ba8d56bf868b75a950bb73f1dbae4', 'faaa98e92d722d0ba7dd22c0aa3913f0', 'f7ce17ee88cdec33973c46c285b944d7', 'ccf770542367f03f276c3d558130f8b4', 'cf51da336a5414031b8fee1b14934c0e', 'e9ee67ab2cccdba5771dea817d9f8136', 'faf6a45b04c24fab1d9b004d9d8d2781', 'e574eb37ea6ee685e1f2a1daf140ac9f', 'e9fd75b68e06c18cb056c98b2e5e5e4e', 'd6ab580443ae008d6a2345809e2bb169', 'd35bd51cdc04c103882d915ba9d043ba', 'f3004f6eb2e5fb8eb7a51049b27f4bf4', 'd8c06e41fedbf387e5a528a89590d5ea', 'e3a1e9f4699dd059d9fa04bac43c622e', 'caff0ebc560479ced735fa1ab17311ec']\n",
      "\n",
      "\n",
      "2d_iou_multi -- percent improved: 0.8413461538461539 avg amount: 1.3700871870809235\n",
      "2d_iou_multi -- percent worse: 0.15865384615384615 avg amount: 0.909914929505947\n",
      "3d_iou -- percent improved: 0.8457831325301205 avg amount: 2.5969982123290785\n",
      "3d_iou -- percent worse: 0.15421686746987953 avg amount: 0.7736093713906593\n",
      "chamfer_L1 -- percent improved: 0.8798076923076923 avg amount: 0.3175025251936568\n",
      "chamfer_L1 -- percent worse: 0.1201923076923077 avg amount: 1.689150174946427\n"
     ]
    }
   ],
   "source": [
    "for class_id in class_ids:\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    evaluation_dir_before = evaluation_dir_before_temp.format(class_id)\n",
    "    evaluation_dir_after = evaluation_dir_after_temp.format(pose_type, class_id)\n",
    "    \n",
    "    results_df_before_raw = pd.read_pickle(os.path.join(evaluation_dir_before, \"eval_results.pkl\"))\n",
    "    results_df_after_raw = pd.read_pickle(os.path.join(evaluation_dir_after, \"eval_results.pkl\"))\n",
    "    print(len(results_df_before_raw))\n",
    "    print(len(results_df_after_raw))\n",
    "    #if pose_type == \"bf\":\n",
    "    #    results_df_before_raw_bf = pd.read_pickle(os.path.join(evaluation_dir_before, \"eval_results_bf_pose.pkl\"))\n",
    "    #    results_df_before_raw = update_2d_iou_input_to_bf(results_df_before_raw, results_df_before_raw_bf)\n",
    "\n",
    "    results_df_before, results_df_after = filter_and_sort_eval_dfs(results_df_before_raw, results_df_after_raw)\n",
    "    results_df_before[\"chamfer_L1\"] = results_df_before[\"chamfer_L1\"] * 10\n",
    "    results_df_after[\"chamfer_L1\"] = results_df_after[\"chamfer_L1\"] * 10\n",
    "\n",
    "    metrics = [\"2d_iou_input\", \"2d_iou_multi\", \"3d_iou\", \"chamfer_L1\"]\n",
    "    delta_df = results_df_after[metrics].reset_index(drop=True) / results_df_before[metrics].reset_index(drop=True)\n",
    "    delta_df = delta_df.replace([np.inf, -np.inf], np.nan)\n",
    "    delta_df[\"chamfer_L1\"] = delta_df[\"chamfer_L1\"].apply(lambda x: (np.nan if x > 50 else x))\n",
    "    delta_df[\"instance\"] = results_df_after[\"instance\"].reset_index(drop=True)\n",
    "    \n",
    "    print(\"{} -> {}\".format(evaluation_dir_before, evaluation_dir_after))\n",
    "    print(\"Note: filtering results from {} to {}\\n\".format(max(len(results_df_before_raw), len(results_df_after_raw)), len(results_df_after)))\n",
    "    #print(results_df_before.mean())\n",
    "    #print(\"\\n -> \\n\")\n",
    "    #print(results_df_after.mean())\n",
    "    print(\"\\n Delta: \\n\")\n",
    "    print((delta_df).mean(skipna=True))\n",
    "    #print((delta_df).median(skipna=True))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"most improved: {}\".format(delta_df.sort_values(\"3d_iou\", ascending=False)[\"instance\"].to_list()[:20]))\n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    #    display(delta_df.sort_values(\"chamfer_L1\", ascending=False))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\")\n",
    "    for metric in [\"2d_iou_multi\", \"3d_iou\", \"chamfer_L1\"]:\n",
    "        if metric in [\"2d_iou_multi\", \"3d_iou\"]:\n",
    "            num_improved = len(delta_df[delta_df[metric]>1])\n",
    "            avg_improve_amt = delta_df[delta_df[metric]>1][metric].mean()\n",
    "            num_worse = len(delta_df[delta_df[metric]<1])\n",
    "            avg_worse_amt = delta_df[delta_df[metric]<1][metric].mean()\n",
    "        else:\n",
    "            num_improved = len(delta_df[delta_df[metric]<1])\n",
    "            avg_improve_amt = delta_df[delta_df[metric]<1][metric].mean()\n",
    "            num_worse = len(delta_df[delta_df[metric]>1])\n",
    "            avg_worse_amt = delta_df[delta_df[metric]>1][metric].mean()\n",
    "        print(\"{} -- percent improved: {} avg amount: {}\".format(metric, num_improved/(num_improved+num_worse), avg_improve_amt))\n",
    "        print(\"{} -- percent worse: {} avg amount: {}\".format(metric, num_worse/(num_improved+num_worse), avg_worse_amt))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T10:40:17.541265Z",
     "start_time": "2020-10-08T10:40:16.921046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(delta_df)\n",
    "delta_df.plot.scatter(x=\"2d_iou_input\", y=\"2d_iou_multi\")\n",
    "delta_df.plot.scatter(x=\"2d_iou_input\", y=\"3d_iou\")\n",
    "delta_df.plot.scatter(x=\"2d_iou_input\", y=\"chamfer_L1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T08:05:04.017042Z",
     "start_time": "2020-10-08T08:05:03.918004Z"
    }
   },
   "outputs": [],
   "source": [
    "#display(results_df_before)\n",
    "iou_2d_delta_threshold = 0.17\n",
    "filtered_delta_df = delta_df[delta_df[\"2d_iou_input\"]<iou_2d_delta_threshold]\n",
    "print((filtered_delta_df).mean())\n",
    "print(len(filtered_delta_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T11:15:06.645494Z",
     "start_time": "2020-10-08T11:15:05.097260Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_df = compare_before_after_refinement(results_df_before, results_df_after)\n",
    "comp_df.hist(column=\"iou_3d_delta\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
