{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:00:04.750740Z",
     "start_time": "2020-10-19T23:00:04.574501Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:00:05.363495Z",
     "start_time": "2020-10-19T23:00:04.752323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:00:09.340386Z",
     "start_time": "2020-10-19T23:00:05.365319Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pprint\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from utils import utils\n",
    "from utils import eval_utils\n",
    "import deformation.losses as def_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T00:32:53.964475Z",
     "start_time": "2020-10-11T00:32:53.659161Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# processing pose quality annotations\n",
    "import xmltodict\n",
    "pose_annotation_path = \"notebooks/pix3d_chair_occnet_pose_quality_annotations.xml\"\n",
    "# processing xml from cvat\n",
    "# https://github.com/openvinotoolkit/cvat\n",
    "with open (pose_annotation_path, 'r') as f:\n",
    "    f = f.read()\n",
    "d = dict(xmltodict.parse(f))\n",
    "\n",
    "pose_annotation_dict = {}\n",
    "pose_quality_stats = {\"num_good\":0, \"num_medium\":0, \"num_bad\":0}\n",
    "for entry in d['annotations']['image']:\n",
    "    anno_dict = dict(entry)\n",
    "    entry_label = dict(anno_dict['tag'])['@label']\n",
    "    pose_annotation_dict[anno_dict['@name'].replace('.png', '')] = entry_label\n",
    "    pose_quality_stats[\"num_{}\".format(entry_label)] += 1\n",
    "    \n",
    "pprint.pprint(pose_quality_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T06:14:04.407912Z",
     "start_time": "2020-09-30T06:14:04.384309Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def filter_eval_df_by_quality(original_eval_df, pose_quality_dict, allowed_qualities=[\"good\"]):\n",
    "    instances_to_consider = [instance for instance in pose_quality_dict if pose_quality_dict[instance] in allowed_qualities]    \n",
    "    filtered_df = original_eval_df[original_eval_df[\"instance\"].isin(instances_to_consider)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:00:09.368264Z",
     "start_time": "2020-10-19T23:00:09.341978Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_before_after_refinement(results_df_before, results_df_after):\n",
    "    \n",
    "    statistics = {\"num_3d_iou_improved\":0, \"avg_improve_amt\": 0, \"avg_improve_before_2d_iou\":0, \"num_3d_iou_worse\":0,  \"avg_worse_amt\":0, \"avg_worse_before_2d_iou\":0}\n",
    "    improved_instances = []\n",
    "    worse_instances = []\n",
    "    comparision_df = pd.DataFrame()\n",
    "    for instance in list(results_df_after[\"instance\"]):\n",
    "        if instance in list(results_df_before[\"instance\"]):\n",
    "            before_result = results_df_before[results_df_before[\"instance\"]==instance]\n",
    "            before_3d_iou = float(before_result[\"3d_iou\"])\n",
    "            #before_2d_iou = float(before_result[\"2d_iou\"])\n",
    "            after_result = results_df_after[results_df_after[\"instance\"]==instance]\n",
    "            after_3d_iou = float(after_result[\"3d_iou\"])\n",
    "            #after_2d_iou = float(after_result[\"2d_iou\"])\n",
    "\n",
    "            #iou_2d_change = after_2d_iou - before_2d_iou\n",
    "            iou_3d_change = after_3d_iou - before_3d_iou\n",
    "\n",
    "            if math.isnan(iou_3d_change):\n",
    "                statistics[\"num_3d_iou_worse\"] += 1\n",
    "                continue\n",
    "            elif iou_3d_change > 0:\n",
    "                statistics[\"num_3d_iou_improved\"] += 1\n",
    "                statistics[\"avg_improve_amt\"] += iou_3d_change\n",
    "                #statistics[\"avg_improve_before_2d_iou\"] += before_2d_iou\n",
    "                improved_instances.append(instance)\n",
    "            else:\n",
    "                statistics[\"num_3d_iou_worse\"] += 1\n",
    "                statistics[\"avg_worse_amt\"] += iou_3d_change\n",
    "                #statistics[\"avg_worse_before_2d_iou\"] += before_2d_iou\n",
    "                worse_instances.append(instance)\n",
    "            comparision_df = comparision_df.append({\"instance\": instance, \"iou_3d_delta\": iou_3d_change}, ignore_index=True)\n",
    "\n",
    "    statistics[\"avg_improve_amt\"] /= statistics[\"num_3d_iou_improved\"]\n",
    "    statistics[\"avg_improve_before_2d_iou\"] /= statistics[\"num_3d_iou_improved\"]\n",
    "    statistics[\"avg_worse_amt\"] /= statistics[\"num_3d_iou_worse\"]\n",
    "    statistics[\"avg_worse_before_2d_iou\"] /= statistics[\"num_3d_iou_worse\"]\n",
    "            \n",
    "    pprint.pprint(statistics)\n",
    "    #print(\"example improved instances\")\n",
    "    #print(improved_instances[:100])\n",
    "    #print(\"example worse instances\")\n",
    "    #print(worse_instances[:100])\n",
    "    return comparision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:00:09.392705Z",
     "start_time": "2020-10-19T23:00:09.369381Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_eval_df_warnings(original_df, warnings_to_filter=[\"NaN nodes\", \"compute_iou_3d: gt mesh < 200 occupancies\", \"compute_iou_3d: rec mesh < 200 occupancies\"]):\n",
    "    filter_array = []\n",
    "    warnings_list = original_df[\"eval_warnings\"].tolist()\n",
    "    for i in range(len(original_df)):\n",
    "        warnings = warnings_list[i]\n",
    "        keep=True\n",
    "        for warning in warnings:\n",
    "            if warning in warnings_to_filter:\n",
    "                keep=False\n",
    "        filter_array.append(keep)\n",
    "    return original_df[filter_array]\n",
    "\n",
    "def filter_and_sort_eval_dfs(df1, df2):\n",
    "    df1 = filter_eval_df_warnings(df1)\n",
    "    df2 = filter_eval_df_warnings(df2)\n",
    "    df1_instances = df1[\"instance\"].tolist()\n",
    "    df2_instances = df2[\"instance\"].tolist()\n",
    "    \n",
    "    df1_filters = [(True if df1_instance in df2_instances else False) for df1_instance in df1_instances]\n",
    "    df1_filtered = df1[df1_filters].sort_values(by=\"instance\")\n",
    "    \n",
    "    df2_filters = [(True if df2_instance in df1_instances else False) for df2_instance in df2_instances]\n",
    "    df2_filtered = df2[df2_filters].sort_values(by=\"instance\")\n",
    "    \n",
    "    return df1_filtered, df2_filtered\n",
    "\n",
    "def update_2d_iou_input_to_bf(original_df, bf_2d_iou_df):\n",
    "    if (original_df[\"instance\"].tolist() != bf_2d_iou_df[\"instance\"].tolist() ):\n",
    "        raise ValueError(\"Instances don't match\")\n",
    "    original_df[\"2d_iou_input\"] = bf_2d_iou_df[\"2d_iou_input\"]\n",
    "    return original_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:06:24.165477Z",
     "start_time": "2020-10-19T23:06:24.141323Z"
    }
   },
   "outputs": [],
   "source": [
    "# shapenet\n",
    "#class_ids = [\"02691156\", \"02828884\", \"02933112\", \"02958343\", \"03001627\", \"03211117\", \"03636649\", \"03691459\", \"04090263\", \"04256520\", \"04379243\", \"04401088\", \"04530566\"]\n",
    "class_ids = [\"02933112\"]\n",
    "# pix2mesh\n",
    "evaluation_dir_before_temp = \"/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders/{}/rgba\"\n",
    "evaluation_dir_after_temp = \"data/refinements/shapenet_pix2mesh_refinements/{}_pose/{}\"\n",
    "# occnet\n",
    "#evaluation_dir_before_temp = \"/home/svcl-oowl/brandon/research/occupancy_networks/out/pytorch3d_renders/{}/generation/meshes\"\n",
    "#evaluation_dir_after_temp = \"data/refinements/shapenet_occnet_refinements/{}_pose/{}\"\n",
    "\n",
    "# pix3d\n",
    "#evaluation_dir_before_temp = \"/home/svcl-oowl/brandon/research/occupancy_networks/out/pix3d/{}/generation/meshes\"\n",
    "#evaluation_dir_after_temp = \"data/refinements/pix3d_occnet_refinements/{}_pose/{}\"\n",
    "#class_ids = [\"bed\", \"bookcase\", \"chair\", \"desk\", \"misc\", \"sofa\", \"table\",\"tool\", \"wardrobe\"]\n",
    "\n",
    "pose_type = \"gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:06:25.921954Z",
     "start_time": "2020-10-19T23:06:25.533901Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "190\n",
      "190\n",
      "/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders/02933112/rgba -> data/refinements/shapenet_pix2mesh_refinements/gt_pose/02933112\n",
      "Note: filtering results from 190 to 185\n",
      "\n",
      "\n",
      " Delta: \n",
      "\n",
      "2d_iou_input    1.098962\n",
      "2d_iou_multi    1.053528\n",
      "3d_iou          1.036923\n",
      "chamfer_L1      0.803513\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "most improved: ['e72235ca5b0f9b5de485c93908cf58c1', 'fdf32559c6b7a6643fe047712e43e185', 'cdf33719d80e3f1dadecb2bfe4fe7f60', 'd7fe9a6bf2c5ad924c62bee40dcdc539', 'bd2bcee265b1ee1c7c373e0e7470a338', 'd0af907a612856e964b62a9cc93b56f5', 'b13778ff6594e980605de7eae9f0b0f4', 'bc7973150ac25b1ce08dea88cca8641e', 'c0d2f9960e0db8957ed335507280450f', 'd4a7b45abac7a39c59350d819542ec7', 'b12af552392f92b476e9713f57a5fcb6', 'd6242003931d0a27824662341ce2b233', 'cdc2c14b62e110fbf8bf793ac0a3a901', 'b4cb08749e099f0a899736e5d685d0c2', 'ba6599d00e879e11c59350d819542ec7', 'b572114b0944ac203fe047712e43e185', 'b67d58cd774ebeaea480742f4529182b', 'bcee1a76f453723c4cc1952ae0d6e81a', 'b29de5206eb16c146ec91c2f4565a1ff', 'dbcf0d09a1cef0aecfaf287992b2065b']\n",
      "\n",
      "\n",
      "2d_iou_multi -- percent improved: 0.9567567567567568 avg amount: 1.056600994301283\n",
      "2d_iou_multi -- percent worse: 0.043243243243243246 avg amount: 0.9855309847806559\n",
      "3d_iou -- percent improved: 0.6594594594594595 avg amount: 1.1229379509731476\n",
      "3d_iou -- percent worse: 0.34054054054054056 avg amount: 0.8703529855534171\n",
      "chamfer_L1 -- percent improved: 0.8810810810810811 avg amount: 0.7601446092836469\n",
      "chamfer_L1 -- percent worse: 0.11891891891891893 avg amount: 1.124832300029131\n"
     ]
    }
   ],
   "source": [
    "for class_id in class_ids:\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    evaluation_dir_before = evaluation_dir_before_temp.format(class_id)\n",
    "    evaluation_dir_after = evaluation_dir_after_temp.format(pose_type, class_id)\n",
    "    \n",
    "    results_df_before_raw = pd.read_pickle(os.path.join(evaluation_dir_before, \"eval_results.pkl\"))\n",
    "    results_df_after_raw = pd.read_pickle(os.path.join(evaluation_dir_after, \"eval_results.pkl\"))\n",
    "    print(len(results_df_before_raw))\n",
    "    print(len(results_df_after_raw))\n",
    "    #if pose_type == \"bf\":\n",
    "    #    results_df_before_raw_bf = pd.read_pickle(os.path.join(evaluation_dir_before, \"eval_results_bf_pose.pkl\"))\n",
    "    #    results_df_before_raw = update_2d_iou_input_to_bf(results_df_before_raw, results_df_before_raw_bf)\n",
    "\n",
    "    results_df_before, results_df_after = filter_and_sort_eval_dfs(results_df_before_raw, results_df_after_raw)\n",
    "    results_df_before[\"chamfer_L1\"] = results_df_before[\"chamfer_L1\"] * 10\n",
    "    results_df_after[\"chamfer_L1\"] = results_df_after[\"chamfer_L1\"] * 10\n",
    "\n",
    "    metrics = [\"2d_iou_input\", \"2d_iou_multi\", \"3d_iou\", \"chamfer_L1\"]\n",
    "    delta_df = results_df_after[metrics].reset_index(drop=True) / results_df_before[metrics].reset_index(drop=True)\n",
    "    delta_df = delta_df.replace([np.inf, -np.inf], np.nan)\n",
    "    delta_df[\"chamfer_L1\"] = delta_df[\"chamfer_L1\"].apply(lambda x: (np.nan if x > 50 else x))\n",
    "    delta_df[\"instance\"] = results_df_after[\"instance\"].reset_index(drop=True)\n",
    "    \n",
    "    print(\"{} -> {}\".format(evaluation_dir_before, evaluation_dir_after))\n",
    "    print(\"Note: filtering results from {} to {}\\n\".format(max(len(results_df_before_raw), len(results_df_after_raw)), len(results_df_after)))\n",
    "    #print(results_df_before.mean())\n",
    "    #print(\"\\n -> \\n\")\n",
    "    #print(results_df_after.mean())\n",
    "    print(\"\\n Delta: \\n\")\n",
    "    print((delta_df).mean(skipna=True))\n",
    "    #print((delta_df).median(skipna=True))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"most improved: {}\".format(delta_df.sort_values(\"3d_iou\", ascending=False)[\"instance\"].to_list()[:20]))\n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    #    display(delta_df.sort_values(\"chamfer_L1\", ascending=False))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\")\n",
    "    for metric in [\"2d_iou_multi\", \"3d_iou\", \"chamfer_L1\"]:\n",
    "        if metric in [\"2d_iou_multi\", \"3d_iou\"]:\n",
    "            num_improved = len(delta_df[delta_df[metric]>1])\n",
    "            avg_improve_amt = delta_df[delta_df[metric]>1][metric].mean()\n",
    "            num_worse = len(delta_df[delta_df[metric]<1])\n",
    "            avg_worse_amt = delta_df[delta_df[metric]<1][metric].mean()\n",
    "        else:\n",
    "            num_improved = len(delta_df[delta_df[metric]<1])\n",
    "            avg_improve_amt = delta_df[delta_df[metric]<1][metric].mean()\n",
    "            num_worse = len(delta_df[delta_df[metric]>1])\n",
    "            avg_worse_amt = delta_df[delta_df[metric]>1][metric].mean()\n",
    "        print(\"{} -- percent improved: {} avg amount: {}\".format(metric, num_improved/(num_improved+num_worse), avg_improve_amt))\n",
    "        print(\"{} -- percent worse: {} avg amount: {}\".format(metric, num_worse/(num_improved+num_worse), avg_worse_amt))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T10:40:17.541265Z",
     "start_time": "2020-10-08T10:40:16.921046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(delta_df)\n",
    "delta_df.plot.scatter(x=\"2d_iou_input\", y=\"2d_iou_multi\")\n",
    "delta_df.plot.scatter(x=\"2d_iou_input\", y=\"3d_iou\")\n",
    "delta_df.plot.scatter(x=\"2d_iou_input\", y=\"chamfer_L1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T08:05:04.017042Z",
     "start_time": "2020-10-08T08:05:03.918004Z"
    }
   },
   "outputs": [],
   "source": [
    "#display(results_df_before)\n",
    "iou_2d_delta_threshold = 0.17\n",
    "filtered_delta_df = delta_df[delta_df[\"2d_iou_input\"]<iou_2d_delta_threshold]\n",
    "print((filtered_delta_df).mean())\n",
    "print(len(filtered_delta_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T11:15:06.645494Z",
     "start_time": "2020-10-08T11:15:05.097260Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_df = compare_before_after_refinement(results_df_before, results_df_after)\n",
    "comp_df.hist(column=\"iou_3d_delta\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
