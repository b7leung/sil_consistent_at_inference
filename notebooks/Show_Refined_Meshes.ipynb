{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:24:10.664286Z",
     "start_time": "2020-10-30T06:24:10.635810Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "notebook_fixed_dir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:24:11.218184Z",
     "start_time": "2020-10-30T06:24:11.206882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svcl-oowl/brandon/research/sil_consistent_at_inference\n"
     ]
    }
   ],
   "source": [
    "# this cell can only be called once\n",
    "import os\n",
    "if not notebook_fixed_dir:\n",
    "    os.chdir('..')\n",
    "    notebook_fixed_dir = True\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:24:14.585425Z",
     "start_time": "2020-10-30T06:24:12.264383Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "\n",
    "from utils import general_utils\n",
    "from utils import visualization_tools\n",
    "from utils.eval_utils import eval_metrics\n",
    "#from evaluation import compute_iou_2d, compute_iou_2d_given_pose, compute_iou_3d, compute_chamfer_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:24:14.627967Z",
     "start_time": "2020-10-30T06:24:14.587372Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# displays meshes at the predicted pose\n",
    "def show_meshes(input_dir_img, input_dir_mesh, refined_models_dir, gt_shapes_dict, device, only_show_instances=None, num_novel_view=3,\n",
    "                metrics_to_eval=[\"2d_iou_input\", \"2d_iou_multi\", \"3d_iou\",\"chamfer_L1\"], num_sample_points=900000):\n",
    "    \n",
    "\n",
    "    # combining all cached predicted poses\n",
    "    pred_poses_dict = {}\n",
    "    pred_pose_paths = list(Path(refined_models_dir).rglob('pred_poses.p'))\n",
    "    for pred_pose_path in pred_pose_paths:\n",
    "        curr_cache = pickle.load(open(pred_pose_path, \"rb\"))\n",
    "        pred_poses_dict = {**pred_poses_dict, **curr_cache}\n",
    "    \n",
    "    # getting paths of all processed meshes, keyed by instance name\n",
    "    processed_paths = list(Path(refined_models_dir).rglob('*.obj'))\n",
    "    processed_paths_dict = {}\n",
    "    for path in processed_paths:\n",
    "        instance_name = str(path).split('/')[-1][:-4]\n",
    "        if instance_name not in processed_paths_dict:\n",
    "            processed_paths_dict[instance_name] = [path]\n",
    "        else:\n",
    "            processed_paths_dict[instance_name].append(path)\n",
    "    \n",
    "    for instance_name in processed_paths_dict:\n",
    "        if only_show_instances is None or instance_name in only_show_instances:\n",
    "            for processed_mesh_path in processed_paths_dict[instance_name]:\n",
    "                print(processed_mesh_path)\n",
    "            \n",
    "                input_image = Image.open(os.path.join(input_dir_img, instance_name+\".png\"))\n",
    "                original_mesh_path = os.path.join(input_dir_mesh, instance_name+\".obj\")\n",
    "                with torch.no_grad():\n",
    "                    mesh_original = general_utils.load_untextured_mesh(original_mesh_path, device)\n",
    "                    mesh_processed = general_utils.load_untextured_mesh(processed_mesh_path, device)\n",
    "                \n",
    "                pred_dist = pred_poses_dict[instance_name]['dist']\n",
    "                pred_elev = pred_poses_dict[instance_name]['elev']\n",
    "                pred_azim = pred_poses_dict[instance_name]['azim']\n",
    "                \n",
    "                # computing performance metrics\n",
    "                if len(metrics_to_eval) > 0:\n",
    "                    mesh_original_trimesh = trimesh.load(original_mesh_path)\n",
    "                    mesh_processed_trimesh = trimesh.load(processed_mesh_path)\n",
    "                    \n",
    "                    gt_mesh_path = gt_shapes_dict[instance_name]\n",
    "                    with torch.no_grad():\n",
    "                        mesh_gt = general_utils.load_untextured_mesh(gt_mesh_path, device)\n",
    "                    mesh_gt_trimesh = trimesh.load(gt_mesh_path)\n",
    "                    \n",
    "                    metrics_dict_before, _ = eval_metrics(input_image, mesh_original_trimesh, mesh_original, mesh_gt_trimesh, mesh_gt,\n",
    "                                                          device, metrics_to_eval, pred_azim, pred_elev, pred_dist, num_sample_points=num_sample_points)\n",
    "                    metrics_dict_after, _ = eval_metrics(input_image, mesh_processed_trimesh, mesh_processed, mesh_gt_trimesh, mesh_gt,\n",
    "                                                         device, metrics_to_eval, pred_azim, pred_elev, pred_dist, num_sample_points=num_sample_points)\n",
    "                    \n",
    "                    print(\"Metrics before refinement -- {}\".format(metrics_dict_before))\n",
    "                    print(\"Metrics after refinement -- {}\".format(metrics_dict_after))\n",
    "                \n",
    "                visualization_tools.show_refinement_results(input_image, mesh_original, mesh_processed, pred_dist, pred_elev, pred_azim, device, num_novel_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:25:16.216992Z",
     "start_time": "2020-10-30T06:25:16.188921Z"
    }
   },
   "outputs": [],
   "source": [
    "# shapenet\n",
    "class_name = \"02933112\"\n",
    "gt_shapes_list_path = \"data/gt_shapes_path_lists/shapenet_{}_gt_shapes.lst\".format(class_name)\n",
    "input_dir_img = \"data/input_images/pytorch3d_shapenet_renders/{}/rgba\".format(class_name)\n",
    "refinement_type = \"gt_pose\"\n",
    "#refinement_type = \"ablation_2\"\n",
    "\n",
    "# atlasnet\n",
    "#input_dir_mesh = \"/home/svcl-oowl/brandon/research/AtlasNet/data/pytorch_3d_render_recs/{}\".format(class_name)\n",
    "#refined_models_dir = \"data/refinements/shapenet_atlasnet_refinements/gt_pose/{}\".format(class_name)\n",
    "# pix2mesh\n",
    "#input_dir_mesh = \"/home/svcl-oowl/brandon/research/Pixel2Mesh/rec_files/pytorch3d_shapenet_renders/{}/rgba\".format(class_name)\n",
    "#refined_models_dir = \"data/refinements/shapenet_pix2mesh_refinements/gt_pose/{}\".format(class_name)\n",
    "# occnet\n",
    "input_dir_mesh = \"/home/svcl-oowl/brandon/research/occupancy_networks/out/pytorch3d_renders/{}/generation/meshes\".format(class_name)\n",
    "refined_models_dir = \"data/refinements/shapenet_occnet_refinements/{}/{}\".format(refinement_type, class_name)\n",
    "\n",
    "# pix3d occnet gt\n",
    "#class_name = \"wardrobe\"\n",
    "#input_dir_mesh = \"/home/svcl-oowl/brandon/research/occupancy_networks/out/pix3d/{}/generation/meshes\".format(class_name)\n",
    "#input_dir_img = \"data/input_images/pix3d_images_processed_filtered/{}/rgba\".format(class_name)\n",
    "#gt_shapes_list_path = \"data/gt_shapes_path_lists/pix3d_{}_gt_shapes.lst\".format(class_name)\n",
    "#refined_models_dir = \"data/refinements/pix3d_occnet_refinements/gt_pose/{}\".format(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:25:17.393448Z",
     "start_time": "2020-10-30T06:25:17.363239Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "gt_shapes_dict = {}\n",
    "with open(gt_shapes_list_path, 'r') as f:\n",
    "    f = f.read().split('\\n')\n",
    "    for line in f:\n",
    "        if line != \"\":\n",
    "            gt_shapes_dict[line.split(\" \")[0]] = line.split(\" \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T03:49:44.129881Z",
     "start_time": "2020-10-29T03:49:44.101851Z"
    }
   },
   "outputs": [],
   "source": [
    "#instances = ['fb402a36e91ab1b44e7761521d3c6953', 'ddd6c2a51c25036c8a43cd65b179a1ff', 'd56fba80d39bdff738decdbba236bc1d', 'f8d8b590a0dcd399718ac2a6ddb54499', 'f3cbfb52ea1c907a850e00840470903a', 'f25ffb9cf92236fb9671f5163e7f6535', 'e332fb3eb2c4016ec1f9d235878ff0a9', 'd54a694d514b1911844ac48bcfce34', 'd4cc520929730248642fa8402286a797', 'fbc7afa847c30a4c183bb3a05fac486f', 'dbd589812bda0b1ebab624e35355496d', 'f6b96f56212f55363023a5c0cae3fffe', 'e4bdcd6baad501ab2a8b9d468136b0a1', 'ef6db5bcb6bb96ddd2f0cc036969ee4f', 'f2f6684e930651df3dffb45955223d25', 'e9704a563a5a0a3f5a4b8d382b9decda', 'e53547a01129eef87eda1e12bd28fb7', 'e06d3e6c1fb4b208cb7c15fd62c3982e', 'e4b0599a9d06f7ae39cb1b92881e8e76', 'fb0f2907b977e7cb67c5e3041553656b']\n",
    "#instances = ['1359', '1422', '0649', '0581', '0863', '0859', '2868', '2475', '0770', '0652', '0647', '0966', '0661', '2931', '0927', '3313', '2969', '0744', '2944', '0672']\n",
    "#instances = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T06:25:43.982889Z",
     "start_time": "2020-10-30T06:25:43.953058Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#instances = random.sample([str(path).split('/')[-1].replace('.obj',\"\") for path in list(Path(refined_models_dir).rglob('*.obj'))], 180)\n",
    "instances=[\"79a8b5fdd40e1b1d20768660cf080d12\", \"eb2843ff62280f5320768660cf080d12\", \"5ff47fe4724d0c9320768660cf080d12 \"]\n",
    "#m = [\"2d_iou_input\", \"2d_iou_multi\", \"3d_iou\",\"chamfer_L1\"]\n",
    "m = []\n",
    "show_meshes(input_dir_img, input_dir_mesh, refined_models_dir, gt_shapes_dict, device, only_show_instances=instances, metrics_to_eval=m, num_sample_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T02:44:45.089262Z",
     "start_time": "2020-09-29T02:43:33.530772Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show training loss info\n",
    "# getting paths of all loss info pickled files\n",
    "input_dir_mesh = cfg['dataset']['input_dir_mesh']\n",
    "output_dir = \"{}_{}\".format(input_dir_mesh, exp_name)\n",
    "cached_loss_info_paths = list(Path(output_dir).rglob('loss_info.p'))\n",
    "\n",
    "for path in cached_loss_info_paths:\n",
    "    dataset_loss_info = pickle.load(open(path, \"rb\"))\n",
    "    for instance_name in dataset_loss_info:\n",
    "        loss_info = dataset_loss_info[instance_name]\n",
    "        loss_info.plot.line(x='iteration', y='total_loss', title=\"{}\".format(instance_name))\n",
    "        #loss_info.plot.line(x='iteration', y='sil_loss')\n",
    "        #loss_info.plot.line(x='iteration', y='img_sym_loss')\n",
    "        #loss_info.plot.line(x='iteration', y='vertex_sym_loss')\n",
    "        #loss_info.plot.line(x='iteration', y='l2_loss')\n",
    "        #loss_info.plot.line(x='iteration', y='lap_smoothness_loss')\n",
    "        #loss_info.plot.line(x='iteration', y='normal_consistency_loss')\n",
    "        #loss_info.plot.line(x='iteration', y='semantic_dis_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:standard] *",
   "language": "python",
   "name": "conda-env-standard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
