
training:
  semantic_dis_num_render: 8
  semantic_dis_lam: 0 # semantic discriminator loss weight

  img_sym_num_azim: 1 #[1*]
  img_sym_lam: 50 # image-based symmetry loss [100*]

  sil_lam: 100 # silouette loss. [5*]
  vertex_sym_lam: 0 # vertex-based symmetry loss [0.1*]

  l2_lam: 0 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]

semantic_dis_training:
  save_model_every: 20 # save model every n adversarial iterations

  # training details
  real_label_offset: 0
  label_noise: 0
  batch_size: 16
  adv_iterations: 200
  dis_epochs_per_iteration: 0
  gen_epochs_per_iteration: 1
  num_batches_gen_train: 30
  early_stop_dis_acc: 0.8 # stops training of discriminator early if avg acc of last 10 batches is >= this threshold, in [0,1]. to disable,set to -1

  # generator options
  deform_net_type: "gcn_full_res" # {pointnet, gcn, gcn_pn, gcn_full}
  gen_data_type: "standard" # {standard, deform_sphere_debug}
  gen_pointnet_lr: 0.001
  gen_gcn_lr: 0.001
  gen_decay: 0.0001

  # discriminator options 
  dis_type: "points" # type of discriminator input, in {renders, points}
  dropout_p: 0 # amount of dropout to use in discriminator network

  # for dis_type = pointnet
  recompute_cache: false
  dis_points_lr: 0.00003 #0.0001
  dis_points_decay: 0.0001
  dis_points_encoder: "rgan" # in {pointnet, fc, rgan}

  # for dis_type = renders
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render
  randomize_dis_inputs: true
 
