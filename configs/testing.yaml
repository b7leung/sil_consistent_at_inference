#dataset:
#  input_dir_mesh: "data/test_dataset_one" # Path to folder with meshes to postprocess.
#  input_dir_img: "data/test_dataset_one" # Path to folder with images for meshes.


training:
  num_iterations: 400
  learning_rate: 0.00008 #[0.00001*]

  semantic_dis_num_render: 8
  semantic_dis_lam: 10 # semantic discriminator loss weight

  img_sym_num_azim: 1 #[1*]
  img_sym_lam: 50 # image-based symmetry loss [100*]

  sil_lam: 5 # silouette loss. [5*]
  vertex_sym_lam: 0.1 # vertex-based symmetry loss [0.1*]

  l2_lam: 0.5 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]

semantic_dis_training:
  dis_type: "renders" # type of discriminator branch, in {renders, pointnet}

  batch_size: 16
  adv_iterations: 3
  dis_epochs_per_iteration: 2
  gen_epochs_per_iteration: 2
  num_batches_gen_train: 3

  label_noise: 0
  real_label_offset: 0.05
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256}
  randomize_dis_inputs: true
  gen_small_weights_init: false # note: this is overided if gen_weight_path is specified

  save_model_every: 2 # save model every n adversarial iterations
  num_mesh_eval: 10


