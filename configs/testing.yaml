dataset:
  input_dir_mesh: "data/test_dataset_one" # Path to folder with meshes to postprocess.
  input_dir_img: "data/test_dataset_one" # Path to folder with images for meshes.


# parameters for test-time optimization
refinement:
  num_iterations: 700
  learning_rate: 0.00008 #[0.00001*]


# loss function parameters
training:
  semantic_dis_lam: 0 # semantic discriminator loss weight

  img_sym_num_azim: 1 #[1*]
  img_sym_lam: 100 # image-based symmetry loss [100*]

  sil_lam: 1 # silouette loss. [5*]
  vertex_sym_lam: 0.1 # vertex-based symmetry loss [0.1*]

  l2_lam: 1 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]


# parameters for the generator and discriminator
semantic_dis_training:
  dis_weight_path: ""
  gen_weight_path: ""

  # generator options
  deform_net_type: "pointnet" # {pointnet, gcn}
  
  # discriminator options 
  dis_type: "points" # type of discriminator input, in {renders, points, mesh}

  # for dis_type = points
  dis_points_encoder: "rgan" # in {pointnet, fc, rgan}

  # for dis_type = renders
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render



