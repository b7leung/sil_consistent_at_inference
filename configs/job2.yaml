
training:
  num_iterations: 400
  learning_rate: 0.00008 #[0.00001*]

  semantic_dis_num_render: 8
  semantic_dis_lam: 10 # semantic discriminator loss weight

  img_sym_num_azim: 1 #[1*]
  img_sym_lam: 50 # image-based symmetry loss [100*]

  sil_lam: 0 # silouette loss. [5*]
  vertex_sym_lam: 0.1 # vertex-based symmetry loss [0.1*]

  l2_lam: 0.5 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]

semantic_dis_training:
  # training details
  real_label_offset: 0.00
  label_noise: 0
  batch_size: 16
  adv_iterations: 1
  dis_epochs_per_iteration: 200
  gen_epochs_per_iteration: 3
  num_batches_gen_train: 30

  # discriminator options 
  dis_type: "renders" # type of discriminator input, in {renders, pointnet}
  dropout_p: 0.8 # amount of dropout to use in discriminator network

  # for dis_type = pointnet
  recompute_cache: false

  # for dis_type = renders
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render
  randomize_dis_inputs: true
 



