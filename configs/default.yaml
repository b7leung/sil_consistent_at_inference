dataset:
  input_dir_mesh: "data/onet_chair_pix3d_dann_simplified" # Path to folder with meshes to postprocess.
  input_dir_img: "data/img_pix3d_chair/chair" # Path to folder with images for meshes.


brute_force_pose_est:
  num_azims: 20
  num_elevs: 20
  num_dists: 40


model:
  point_encoder: "ResnetPointnet" # {ResnetPointnet, ResnetPointnetExtended}
  image_encoder: "Resnet18" # {Resnet18, Resnet34}
  deformation_decoder: "FCStandard" # {FCStandard, FC_BN}
  latent_dim_pointnet: 512
  latent_dim_resnet: 256
  decoder_dim: 1024


# parameters for test-time optimization
refinement:
  num_iterations: 400
  learning_rate: 0.00007


# loss function parameters
training:
  semantic_dis_lam: 0 # semantic discriminator loss weight

  img_sym_num_azim: 3 #[1*]
  img_sym_lam: 75 # image-based symmetry loss [100*]

  sil_lam: 10 # silouette loss. [5*]
  vertex_sym_lam: 0.0 # vertex-based symmetry loss [0.1*]
  vertex_asym: false

  l2_lam: 0 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]


# parameters for the generator and discriminator
semantic_dis_training:
  # basic setup configs
  output_dir: "out" # Path to folder to output saved weights and training pickle
  cache_dir: "caches"
  use_input_mesh_cache: true
  recompute_input_mesh_cache: false
  dis_weight_path: ""
  gen_weight_path: ""
  save_model_every: 200 # save model every n adversarial iterations
  num_mesh_eval: 10
  mesh_num_verts: 1500

  # training details
  gen_small_weights_init: false # note: this is overided if gen_weight_path is specified
  real_label_offset: 0.05
  label_noise: 0
  batch_size: 16
  adv_iterations: 10
  dis_epochs_per_iteration: 30
  gen_epochs_per_iteration: 100
  num_batches_gen_train: -1
  early_stop_dis_acc: -1 # stops training of discriminator early if avg acc of last 10 batches is >= this threshold, in [0,1]. to disable,set to -1


  # generator options
  deform_net_type: "gcn_full" # {pointnet, gcn, gcn_pn, gcn_full, fc_points}
  gen_dir_mesh: ""
  gen_dir_img: ""
  gen_poses: ""
  gen_pointnet_lr: 0.00008
  gen_gcn_lr: 0.00007
  gen_decay: 0.0

  # discriminator options 
  dis_type: "multiview" # type of discriminator input, in {renders, points, multiview}
  dropout_p: 0.8 # amount of dropout to use in discriminator network
  dis_real_shapes_dir: ""
  dis_data_recompute: True
  dis_data_use_cache: True
  dis_data_recreate_cache: True  

  # for dis_type = points
  recompute_cache: false
  dis_points_lr: 0.00001
  dis_points_decay: 0.01
  dis_points_encoder: "rgan" # in {pointnet, fc, rgan}

  # for dis_type = multiview
  dis_mv_azims: [0,45,90,135,180,225,270,315]
  dis_mv_dist: 1.5
  dis_mv_elev: 30
  dis_mv_lighting_mode: ""
  dis_mv_render_sil: True
  dis_mv_img_size: 224
  dis_mv_lr: 0.00001
  dis_mv_decay: 0.01
  dis_mv_backbone: "vgg11"

  # for dis_type = renders
  real_dataset_dir: "data/semantic_dis/real_renders" # Path to folder with rendered images of real 3d models.
  real_dataset_dir_sil: "data/semantic_dis_sil/real_renders" # Path to folder with rendered images of real 3d models.
  fake_dataset_dir: "data/semantic_dis_sil/fake_renders" # Path to folder with rendered images of fake 3d models.
  semantic_dis_num_render: 8
  dis_renders_lr: 0.00001
  dis_renders_decay: 0.01
  transform_dis_inputs: false
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render
  randomize_dis_inputs: true








