dataset:
  input_dir_mesh: "data/onet_chair_pix3d_dann_simplified" # Path to folder with meshes to postprocess.
  input_dir_img: "data/img_pix3d_chair/chair" # Path to folder with images for meshes.


brute_force_pose_est:
  num_azims: 20
  num_elevs: 20
  num_dists: 40


model:
  point_encoder: "ResnetPointnet" # {ResnetPointnet, ResnetPointnetExtended}
  image_encoder: "Resnet18" # {Resnet18, Resnet34}
  deformation_decoder: "FCStandard" # {FCStandard, FC_BN}
  latent_dim_pointnet: 512
  latent_dim_resnet: 256
  decoder_dim: 1024
  output_delta_V: true # if, conceptually, the model should be outputting delta V (just the displacement), or the entire (delta V + V)


# parameters for test-time optimization
refinement:
  num_iterations: 700
  learning_rate: 0.00008 #[0.00001*]


# loss function parameters
training:
  semantic_dis_lam: 0 # semantic discriminator loss weight

  img_sym_num_azim: 1 #[1*]
  img_sym_lam: 0 # image-based symmetry loss [100*]

  sil_lam: 20 # silouette loss. [5*]
  vertex_sym_lam: 0 # vertex-based symmetry loss [0.1*]

  l2_lam: 0 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 0  # laplacian smoothing loss [10*]
  normal_consistency_lam: 0 # normal consistency loss [10*]


# parameters for the generator and discriminator
semantic_dis_training:
  # basic setup configs
  output_dir: "out" # Path to folder to output saved weights and training pickle
  input_dir_pose: "data/onet_chair_pix3d_dann_simplified_processed/pred_poses.p" # path to predicted pose cache dict corresponding to mesh/imgs in input_dir_mesh and input_dir_img
  dataset_meshes_list_path: "data/onet_chair_pix3d_dann_simplified/1502.lst" # path to a file which lists the meshes/imgs to use from input_dir_mesh and input_dir_img. Meshes have to have the same # vertices.
  use_input_mesh_cache: true
  recompute_input_mesh_cache: false
  mesh_num_verts: 1502
  dis_weight_path: ""
  gen_weight_path: ""
  save_model_every: 200 # save model every n adversarial iterations
  num_mesh_eval: 10

  # training details
  gen_small_weights_init: false # note: this is overided if gen_weight_path is specified
  real_label_offset: 0.05
  label_noise: 0
  batch_size: 16
  adv_iterations: 10
  dis_epochs_per_iteration: 30
  gen_epochs_per_iteration: 100
  num_batches_gen_train: 30
  early_stop_dis_acc: -1 # stops training of discriminator early if avg acc of last 10 batches is >= this threshold, in [0,1]. to disable,set to -1


  # generator options
<<<<<<< HEAD
  deform_net_type: "pointnet" # {pointnet, gcn, gcn_pn}
=======
  deform_net_type: "pointnet" # {pointnet, gcn}
>>>>>>> 426e913ac201dfaee15d883f3e3332aec9fed132
  gen_data_type: "standard" # {standard, deform_sphere_debug}
  gen_pointnet_lr: 0.00008
  gen_gcn_lr: 0.00008
  gen_decay: 0.0001

  # discriminator options 
  dis_type: "renders" # type of discriminator input, in {renders, points, mesh}
  dropout_p: 0.8 # amount of dropout to use in discriminator network

  # for dis_type = points
  real_shapes_dir: "/home/svcl-oowl/dataset/ShapeNetCore.v1/03001627"
  sampled_points_path: "data/real_sampled_points/shapenet_chairs_1502.pt"
  recompute_cache: false
  dis_points_lr: 0.00001
  dis_points_decay: 0.01
  dis_points_encoder: "pointnet" # in {pointnet, fc, rgan}
  DEBUG_single_real: false

  # for dis_type = renders
  real_dataset_dir: "data/semantic_dis/real_renders" # Path to folder with rendered images of real 3d models.
  real_dataset_dir_sil: "data/semantic_dis_sil/real_renders" # Path to folder with rendered images of real 3d models.
  fake_dataset_dir: "data/semantic_dis_sil/fake_renders" # Path to folder with rendered images of fake 3d models.
  semantic_dis_num_render: 8
  dis_renders_lr: 0.00001
  dis_renders_decay: 0.01
  transform_dis_inputs: false
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render
  randomize_dis_inputs: true








