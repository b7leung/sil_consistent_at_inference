dataset:
  input_dir_mesh: "data/onet_chair_pix3d_dann_simplified" # Path to folder with meshes to postprocess.
  input_dir_img: "data/img_pix3d_chair/chair" # Path to folder with images for meshes.


brute_force_pose_est:
  num_azims: 20
  num_elevs: 20
  num_dists: 40


model:
  point_encoder: "ResnetPointnet" # {ResnetPointnet, ResnetPointnetExtended}
  image_encoder: "Resnet18" # {Resnet18, Resnet34}
  deformation_decoder: "FCStandard" # {FCStandard, FC_BN}
  latent_dim_pointnet: 512
  latent_dim_resnet: 256
  decoder_dim: 1024


# parameters for test-time optimization
refinement:
  num_iterations: 400
  learning_rate: 0.00007


# loss function parameters
training:
  semantic_dis_lam: 0 # semantic discriminator loss weight

  img_sym_num_azim: 3 #[1*]
  img_sym_lam: 75 # image-based symmetry loss [100*]

  sil_lam: 10 # silouette loss. [5*]
  vertex_sym_lam: 0.0 # vertex-based symmetry loss [0.1*]
  vertex_asym: false

  l2_lam: 0 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]

  def_loss_first_rel: false # deformation loss will be relative to the first foward pass, not the original mesh


# parameters for the generator and discriminator
semantic_dis_training:
  # basic setup configs
  output_dir: "out" # Path to folder to output saved weights and training pickle
  cache_dir: "caches"
  use_input_mesh_cache: true
  recompute_input_mesh_cache: false
  dis_weight_path: ""
  gen_weight_path: ""
  save_model_every: 100 # save model every n adversarial iterations
  save_samples_every: 10 # save and evaluate samples every n adversarial iterations
  num_mesh_batch_eval: 1
  mesh_num_verts: 1500
  num_verts_tolerance: 0 # tolerance for num of verts less than mesh_num_verts (those with more are automatically removed)
  standardize_num_verts: true
  normalize_data: true # normalize pointclouds (real and fake) by centering and contraining to sphere of diameter 1

  # training details
  gen_small_weights_init: false # note: this is overided if gen_weight_path is specified
  real_label_offset: 0.05
  label_noise: 0
  batch_size: 16
  adv_iterations: 5000
  dis_steps_per_iteration: 1
  gen_steps_per_iteration: 1
  num_batches_gen_train: -1
  beta1: 0.5

  # generator options
  deform_net_type: "gcn_full" # {pointnet, gcn, gcn_pn, gcn_full, fc_points}
  gen_dir_mesh: ""
  gen_dir_img: ""
  gen_poses: ""
  gen_pointnet_lr: 0.00008
  gen_gcn_lr: 0.00007
  gen_decay: 0.0

  # discriminator options 
  dis_type: "points" # type of discriminator input, in {renders, points, multiview}
  dis_real_shapes_dir: ""
  dis_data_recompute: True
  dis_data_use_cache: True
  dis_data_recreate_cache: True  

  # for dis_type = points
  recompute_cache: false
  dis_points_lr: 0.00001
  dis_points_decay: 0.01
  dis_points_spectral_norm: True
  dis_points_pooling: "max" # type of pooling to use in pointnet, in {max, avg}

  # for dis_type = multiview
  dis_mv_azims: [0,45,90,135,180,225,270,315]
  dis_mv_dist: 1.5
  dis_mv_elev: 30
  dis_mv_lighting_mode: ""
  dis_mv_render_sil: True
  dis_mv_img_size: 224
  dis_mv_lr: 0.00001
  dis_mv_decay: 0.01
  dis_mv_backbone: "vgg11"

  # for dis_type = renders
  real_dataset_dir: "data/semantic_dis/real_renders" # Path to folder with rendered images of real 3d models.
  real_dataset_dir_sil: "data/semantic_dis_sil/real_renders" # Path to folder with rendered images of real 3d models.
  fake_dataset_dir: "data/semantic_dis_sil/fake_renders" # Path to folder with rendered images of fake 3d models.
  semantic_dis_num_render: 8
  dis_renders_lr: 0.00001
  dis_renders_decay: 0.01
  transform_dis_inputs: false
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render
  randomize_dis_inputs: true








