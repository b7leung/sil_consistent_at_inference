# python postprocess_dataset.py configs/refine.yaml --batch_i 1 --num_batches 5

dataset:
  #input_dir_mesh: "data/test_dataset" # Path to folder with meshes to postprocess.
  #input_dir_img: "data/test_dataset" # Path to folder with images for meshes.
  input_dir_mesh: "data/onet_chair_pix3d_no_DA_simplified" # Path to folder with meshes to postprocess.
  input_dir_img: "data/img_pix3d_chair/chair" # Path to folder with images for meshes.


# parameters for test-time optimization
refinement:
  num_iterations: 400
  learning_rate: 0.0001


# loss function parameters
training:
  semantic_dis_lam: 10 # semantic discriminator loss weight 

  img_sym_num_azim: 1 #[1*]
  img_sym_lam: 75 # image-based symmetry loss [75*]

  sil_lam: 10 # silouette loss. [10*]
  vertex_sym_lam: 0.0 # vertex-based symmetry loss [0.0*]

  l2_lam: 0 # l2 loss on delta v  [1*]
  lap_smoothness_lam: 10  # laplacian smoothing loss [10*]
  normal_consistency_lam: 10 # normal consistency loss [10*]


# parameters for the generator and discriminator
semantic_dis_training:
  dis_weight_path: "out/2020_09_21--07_10_21_job5/semantic_dis_net_weights_99.pt"
  gen_weight_path: "out/2020_09_21--07_10_21_job5/deform_net_weights_99.pt"

  # generator options
  deform_net_type: "gcn_full" # {pointnet, gcn, gcn_full, gcn_pn}
  
  # discriminator options 
  dis_type: "points" # type of discriminator input, in {renders, points, mesh}

  # for dis_type = points
  dis_points_encoder: "rgan" # in {pointnet, fc, rgan}

  # for dis_type = renders
  sil_dis_input: true # whether to discirminate between rendered images, or rendered silhouette.
  dis_input_size: 64 # {64, 128, 256} # size of input image of discriminator. Note that this will increase the gpu memory substantially, so may need to lower semantic_dis_num_render



